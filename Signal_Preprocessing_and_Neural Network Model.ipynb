{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import butter,filtfilt\n",
    "import scipy.signal as sg\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "from scipy.fftpack import fft, ifft\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "\n",
    "from mne import Epochs, pick_types, events_from_annotations\n",
    "from mne.channels import make_standard_montage\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.datasets import eegbci\n",
    "from mne.decoding import CSP\n",
    "py.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import scikitplot as skplt\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessors\n",
    "\n",
    "import scipy.io as sio\n",
    "\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "\n",
    "from mne import Epochs, pick_types, events_from_annotations\n",
    "from mne.channels import make_standard_montage\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.decoding import CSP\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def inputmat(fp):\n",
    "    \"\"\"load .mat file and return m as a dict\"\"\"\n",
    "    mat = sio.loadmat(fp, squeeze_me=True)\n",
    "    td = {}  # create a dict\n",
    "\n",
    "    # Numpy array of size channel_num * points.\n",
    "    td['data'] = mat['cnt'].T  # data\n",
    "    td['freq'] = mat['nfo']['fs'][True][0]  # Sampling frequency\n",
    "\n",
    "    # channel names are necessary information for creating a rawArray.\n",
    "    td['ch_names'] = mat['nfo']['clab'][True][0]\n",
    "\n",
    "    # Position of channels\n",
    "    \n",
    "    td['electrode_x'] = mat['nfo']['xpos'][True][0]\n",
    "    td['electrode_y'] = mat['nfo']['ypos'][True][0]\n",
    "\n",
    "    #make trials by finding trials and its data\n",
    "    td['cue'] = mat['mrk']['pos'][True][0] #time of cue\n",
    "    td['labels'] = mat['mrk']['y'][True][0] #labels of the data\n",
    "    return td\n",
    "\n",
    "\n",
    "def creatEventsArray(fp):\n",
    "    \"\"\"Create events array. The second column default to zero.\"\"\"\n",
    "    td = inputmat(fp)\n",
    "    events = np.zeros((td['labels'].size, 3), int) #here we have made a matrix type array of the size of label.size*3\n",
    "#     print(events)\n",
    "    events[:, 0] = td['cue']  # The first column is the sample number of the event.\n",
    "#     print(events[:, 0])\n",
    "    events[:, 2] = td['labels']  # The third column is the new event value.\n",
    "#     print(events[:, 2])\n",
    "    return events, td['labels']\n",
    "\n",
    "\n",
    "def creatRawArray(fp):\n",
    "    \"\"\"Create a mne.io.RawArray object, data: array, shape (n_channels, n_times)\"\"\"\n",
    "    td = inputmat(fp)\n",
    "    ch_names = td['ch_names'].tolist()\n",
    "    info = mne.create_info(ch_names, td['freq'], 'eeg')  # Create info for raw\n",
    "    raw = mne.io.RawArray(td['data'], info, first_samp=0, copy='auto', verbose=None)\n",
    "    return raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to save the figures\n",
    "\n",
    "\"\"\"\n",
    "image relation with dpi and resolution\n",
    "\n",
    "https://stackoverflow.com/questions/47633546/relationship-between-dpi-and-figure-size\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"classification_png_ex\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=660):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from mne.decoding import CSP\n",
    "from mne.channels import read_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The files c, d, e are the artificial data so we can test out our labels in different ways in them\"\"\"\n",
    "\n",
    "\n",
    "file1 = r'Data/BCICIV_1calib_1000Hz_mat/BCICIV_calib_ds1a_1000Hz.mat'\n",
    "file2 = r'Data/BCICIV_1calib_1000Hz_mat/BCICIV_calib_ds1b_1000Hz.mat'\n",
    "\n",
    "# artificial data files\n",
    "\n",
    "file3 = r'Data/BCICIV_1calib_1000Hz_mat/BCICIV_calib_ds1c_1000Hz.mat'\n",
    "file4 = r'Data/BCICIV_1calib_1000Hz_mat/BCICIV_calib_ds1d_1000Hz.mat'\n",
    "file5 = r'Data/BCICIV_1calib_1000Hz_mat/BCICIV_calib_ds1e_1000Hz.mat'\n",
    "file6 = r'Data/BCICIV_1calib_1000Hz_mat/BCICIV_calib_ds1f_1000Hz.mat'\n",
    "file7 = r'Data/BCICIV_1calib_1000Hz_mat/BCICIV_calib_ds1g_1000Hz.mat'\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"making the file dictionary and channel dictionary for easy pickup\"\"\"\n",
    "fp = {\n",
    "    'ds1a': file1,\n",
    "    'ds1b': file2,\n",
    "    'ds1f': file6,\n",
    "    'ds1g': file7,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" Pick channels if necessary but not needed as we will be deploying a CSP pipeline ahead\"\"\"\n",
    "\n",
    "\n",
    "low_freq, high_freq = 7., 30.\n",
    "tmin, tmax = 0., 3.5\n",
    "\n",
    "event_id = {'left': -1, 'foot': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
    "    plt.legend(loc=\"center right\", fontsize=16) \n",
    "    plt.xlabel(\"Threshold\", fontsize=16)        \n",
    "    plt.grid(True)                              \n",
    "    plt.axis([-50, 150, 0, 1])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    #plt.xlabel('Flase positive Rate (Fall-out)', Fontsize=16)\n",
    "    #plt.ylabel('True positive Rate (Recall)', Fontsize=16)\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_vs_recall(precisions, recalls):\n",
    "    plt.plot(recalls, precisions, \"b-\", linewidth=2)\n",
    "    plt.xlabel(\"Recall\", fontsize=16)\n",
    "    plt.ylabel(\"Precision\", fontsize=16)\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=59, n_times=1905940\n",
      "    Range : 0 ... 1905939 =      0.000 ...  1905.939 secs\n",
      "Ready.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 7 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 7.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 6.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 1651 samples (1.651 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 4.7e+03 (2.2e-16 eps * 59 dim * 3.6e+17  max singular value)\n",
      "    Estimated rank (mag): 59\n",
      "    MAG: rank 59 computed from 59 data channels with 0 projectors\n",
      "Reducing data rank from 59 -> 59\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 4.8e+03 (2.2e-16 eps * 59 dim * 3.6e+17  max singular value)\n",
      "    Estimated rank (mag): 59\n",
      "    MAG: rank 59 computed from 59 data channels with 0 projectors\n",
      "Reducing data rank from 59 -> 59\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Did not find any electrode locations (in the info object), will attempt to use digitization points instead. However, if digitization points do not correspond to the EEG electrodes, this will lead to bad results. Please verify that the sensor locations in the plot are accurate.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No digitization points found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\20121\\OneDrive\\Desktop\\Optimized-BCI\\Signal_Preprocessing_and_Neural Network Model.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/20121/OneDrive/Desktop/Optimized-BCI/Signal_Preprocessing_and_Neural%20Network%20Model.ipynb#X16sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m csp \u001b[39m=\u001b[39m CSP(n_components\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(epochs\u001b[39m.\u001b[39mch_names), reg\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, log\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, norm_trace\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/20121/OneDrive/Desktop/Optimized-BCI/Signal_Preprocessing_and_Neural%20Network%20Model.ipynb#X16sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m csp\u001b[39m.\u001b[39mfit_transform(epochs_data, labels)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/20121/OneDrive/Desktop/Optimized-BCI/Signal_Preprocessing_and_Neural%20Network%20Model.ipynb#X16sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m csp\u001b[39m.\u001b[39;49mplot_patterns(epochs\u001b[39m.\u001b[39;49minfo, ch_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39meeg\u001b[39;49m\u001b[39m\"\u001b[39;49m, units\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPatterns (AU)\u001b[39;49m\u001b[39m\"\u001b[39;49m, size\u001b[39m=\u001b[39;49m\u001b[39m1.5\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/20121/OneDrive/Desktop/Optimized-BCI/Signal_Preprocessing_and_Neural%20Network%20Model.ipynb#X16sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# Use scikit-learn Pipeline with cross_val_score function\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/20121/OneDrive/Desktop/Optimized-BCI/Signal_Preprocessing_and_Neural%20Network%20Model.ipynb#X16sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m clf \u001b[39m=\u001b[39m Pipeline([(\u001b[39m'\u001b[39m\u001b[39mCSP\u001b[39m\u001b[39m'\u001b[39m, csp), (\u001b[39m'\u001b[39m\u001b[39mMLP_C\u001b[39m\u001b[39m'\u001b[39m, MLP_C)])\n",
      "File \u001b[1;32mc:\\Users\\20121\\OneDrive\\Desktop\\Optimized-BCI\\.venv\\lib\\site-packages\\mne\\decoding\\csp.py:353\u001b[0m, in \u001b[0;36mCSP.plot_patterns\u001b[1;34m(self, info, components, average, ch_type, scalings, sensors, show_names, mask, mask_params, contours, outlines, sphere, image_interp, extrapolate, border, res, size, cmap, vlim, cnorm, colorbar, cbar_fmt, units, axes, name_format, nrows, ncols, show)\u001b[0m\n\u001b[0;32m    351\u001b[0m patterns \u001b[39m=\u001b[39m EvokedArray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatterns_\u001b[39m.\u001b[39mT, info, tmin\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m    352\u001b[0m \u001b[39m# the call plot_topomap\u001b[39;00m\n\u001b[1;32m--> 353\u001b[0m fig \u001b[39m=\u001b[39m patterns\u001b[39m.\u001b[39;49mplot_topomap(\n\u001b[0;32m    354\u001b[0m     times\u001b[39m=\u001b[39;49mcomponents,\n\u001b[0;32m    355\u001b[0m     average\u001b[39m=\u001b[39;49maverage,\n\u001b[0;32m    356\u001b[0m     ch_type\u001b[39m=\u001b[39;49mch_type,\n\u001b[0;32m    357\u001b[0m     scalings\u001b[39m=\u001b[39;49mscalings,\n\u001b[0;32m    358\u001b[0m     sensors\u001b[39m=\u001b[39;49msensors,\n\u001b[0;32m    359\u001b[0m     show_names\u001b[39m=\u001b[39;49mshow_names,\n\u001b[0;32m    360\u001b[0m     mask\u001b[39m=\u001b[39;49mmask,\n\u001b[0;32m    361\u001b[0m     mask_params\u001b[39m=\u001b[39;49mmask_params,\n\u001b[0;32m    362\u001b[0m     contours\u001b[39m=\u001b[39;49mcontours,\n\u001b[0;32m    363\u001b[0m     outlines\u001b[39m=\u001b[39;49moutlines,\n\u001b[0;32m    364\u001b[0m     sphere\u001b[39m=\u001b[39;49msphere,\n\u001b[0;32m    365\u001b[0m     image_interp\u001b[39m=\u001b[39;49mimage_interp,\n\u001b[0;32m    366\u001b[0m     extrapolate\u001b[39m=\u001b[39;49mextrapolate,\n\u001b[0;32m    367\u001b[0m     border\u001b[39m=\u001b[39;49mborder,\n\u001b[0;32m    368\u001b[0m     res\u001b[39m=\u001b[39;49mres,\n\u001b[0;32m    369\u001b[0m     size\u001b[39m=\u001b[39;49msize,\n\u001b[0;32m    370\u001b[0m     cmap\u001b[39m=\u001b[39;49mcmap,\n\u001b[0;32m    371\u001b[0m     vlim\u001b[39m=\u001b[39;49mvlim,\n\u001b[0;32m    372\u001b[0m     cnorm\u001b[39m=\u001b[39;49mcnorm,\n\u001b[0;32m    373\u001b[0m     colorbar\u001b[39m=\u001b[39;49mcolorbar,\n\u001b[0;32m    374\u001b[0m     cbar_fmt\u001b[39m=\u001b[39;49mcbar_fmt,\n\u001b[0;32m    375\u001b[0m     units\u001b[39m=\u001b[39;49munits,\n\u001b[0;32m    376\u001b[0m     axes\u001b[39m=\u001b[39;49maxes,\n\u001b[0;32m    377\u001b[0m     time_format\u001b[39m=\u001b[39;49mname_format,\n\u001b[0;32m    378\u001b[0m     nrows\u001b[39m=\u001b[39;49mnrows,\n\u001b[0;32m    379\u001b[0m     ncols\u001b[39m=\u001b[39;49mncols,\n\u001b[0;32m    380\u001b[0m     show\u001b[39m=\u001b[39;49mshow,\n\u001b[0;32m    381\u001b[0m )\n\u001b[0;32m    382\u001b[0m \u001b[39mreturn\u001b[39;00m fig\n",
      "File \u001b[1;32mc:\\Users\\20121\\OneDrive\\Desktop\\Optimized-BCI\\.venv\\lib\\site-packages\\mne\\evoked.py:620\u001b[0m, in \u001b[0;36mEvoked.plot_topomap\u001b[1;34m(self, times, average, ch_type, scalings, proj, sensors, show_names, mask, mask_params, contours, outlines, sphere, image_interp, extrapolate, border, res, size, cmap, vlim, cnorm, colorbar, cbar_fmt, units, axes, time_unit, time_format, nrows, ncols, show)\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[39m@copy_function_doc_to_method_doc\u001b[39m(plot_evoked_topomap)\n\u001b[0;32m    587\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_topomap\u001b[39m(\n\u001b[0;32m    588\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    618\u001b[0m     show\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    619\u001b[0m ):\n\u001b[1;32m--> 620\u001b[0m     \u001b[39mreturn\u001b[39;00m plot_evoked_topomap(\n\u001b[0;32m    621\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m    622\u001b[0m         times\u001b[39m=\u001b[39;49mtimes,\n\u001b[0;32m    623\u001b[0m         ch_type\u001b[39m=\u001b[39;49mch_type,\n\u001b[0;32m    624\u001b[0m         vlim\u001b[39m=\u001b[39;49mvlim,\n\u001b[0;32m    625\u001b[0m         cmap\u001b[39m=\u001b[39;49mcmap,\n\u001b[0;32m    626\u001b[0m         cnorm\u001b[39m=\u001b[39;49mcnorm,\n\u001b[0;32m    627\u001b[0m         sensors\u001b[39m=\u001b[39;49msensors,\n\u001b[0;32m    628\u001b[0m         colorbar\u001b[39m=\u001b[39;49mcolorbar,\n\u001b[0;32m    629\u001b[0m         scalings\u001b[39m=\u001b[39;49mscalings,\n\u001b[0;32m    630\u001b[0m         units\u001b[39m=\u001b[39;49munits,\n\u001b[0;32m    631\u001b[0m         res\u001b[39m=\u001b[39;49mres,\n\u001b[0;32m    632\u001b[0m         size\u001b[39m=\u001b[39;49msize,\n\u001b[0;32m    633\u001b[0m         cbar_fmt\u001b[39m=\u001b[39;49mcbar_fmt,\n\u001b[0;32m    634\u001b[0m         time_unit\u001b[39m=\u001b[39;49mtime_unit,\n\u001b[0;32m    635\u001b[0m         time_format\u001b[39m=\u001b[39;49mtime_format,\n\u001b[0;32m    636\u001b[0m         proj\u001b[39m=\u001b[39;49mproj,\n\u001b[0;32m    637\u001b[0m         show\u001b[39m=\u001b[39;49mshow,\n\u001b[0;32m    638\u001b[0m         show_names\u001b[39m=\u001b[39;49mshow_names,\n\u001b[0;32m    639\u001b[0m         mask\u001b[39m=\u001b[39;49mmask,\n\u001b[0;32m    640\u001b[0m         mask_params\u001b[39m=\u001b[39;49mmask_params,\n\u001b[0;32m    641\u001b[0m         outlines\u001b[39m=\u001b[39;49moutlines,\n\u001b[0;32m    642\u001b[0m         contours\u001b[39m=\u001b[39;49mcontours,\n\u001b[0;32m    643\u001b[0m         image_interp\u001b[39m=\u001b[39;49mimage_interp,\n\u001b[0;32m    644\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[0;32m    645\u001b[0m         axes\u001b[39m=\u001b[39;49maxes,\n\u001b[0;32m    646\u001b[0m         extrapolate\u001b[39m=\u001b[39;49mextrapolate,\n\u001b[0;32m    647\u001b[0m         sphere\u001b[39m=\u001b[39;49msphere,\n\u001b[0;32m    648\u001b[0m         border\u001b[39m=\u001b[39;49mborder,\n\u001b[0;32m    649\u001b[0m         nrows\u001b[39m=\u001b[39;49mnrows,\n\u001b[0;32m    650\u001b[0m         ncols\u001b[39m=\u001b[39;49mncols,\n\u001b[0;32m    651\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\20121\\OneDrive\\Desktop\\Optimized-BCI\\.venv\\lib\\site-packages\\mne\\viz\\topomap.py:2090\u001b[0m, in \u001b[0;36mplot_evoked_topomap\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   2080\u001b[0m mask_params[\u001b[39m\"\u001b[39m\u001b[39mmarkeredgewidth\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m size \u001b[39m/\u001b[39m \u001b[39m2.0\u001b[39m\n\u001b[0;32m   2081\u001b[0m \u001b[39m# setup various parameters, and prepare outlines\u001b[39;00m\n\u001b[0;32m   2082\u001b[0m (\n\u001b[0;32m   2083\u001b[0m     picks,\n\u001b[0;32m   2084\u001b[0m     pos,\n\u001b[0;32m   2085\u001b[0m     merge_channels,\n\u001b[0;32m   2086\u001b[0m     names,\n\u001b[0;32m   2087\u001b[0m     ch_type,\n\u001b[0;32m   2088\u001b[0m     sphere,\n\u001b[0;32m   2089\u001b[0m     clip_origin,\n\u001b[1;32m-> 2090\u001b[0m ) \u001b[39m=\u001b[39m _prepare_topomap_plot(evoked, ch_type, sphere\u001b[39m=\u001b[39;49msphere)\n\u001b[0;32m   2091\u001b[0m outlines \u001b[39m=\u001b[39m _make_head_outlines(sphere, pos, outlines, clip_origin)\n\u001b[0;32m   2092\u001b[0m \u001b[39m# check interactive\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\20121\\OneDrive\\Desktop\\Optimized-BCI\\.venv\\lib\\site-packages\\mne\\viz\\topomap.py:126\u001b[0m, in \u001b[0;36m_prepare_topomap_plot\u001b[1;34m(inst, ch_type, sphere)\u001b[0m\n\u001b[0;32m    123\u001b[0m info\u001b[39m.\u001b[39m_check_consistency()\n\u001b[0;32m    125\u001b[0m \u001b[39m# special case for merging grad channels\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m layout \u001b[39m=\u001b[39m find_layout(info)\n\u001b[0;32m    127\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    128\u001b[0m     ch_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgrad\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    129\u001b[0m     \u001b[39mand\u001b[39;00m layout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    133\u001b[0m     )\n\u001b[0;32m    134\u001b[0m ):\n\u001b[0;32m    135\u001b[0m     picks, _ \u001b[39m=\u001b[39m _pair_grad_sensors(info, layout)\n",
      "File \u001b[1;32mc:\\Users\\20121\\OneDrive\\Desktop\\Optimized-BCI\\.venv\\lib\\site-packages\\mne\\channels\\layout.py:506\u001b[0m, in \u001b[0;36mfind_layout\u001b[1;34m(info, ch_type, exclude)\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(info, (\u001b[39mdict\u001b[39m, Info)):\n\u001b[0;32m    502\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCannot make EEG layout, no measurement info \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mwas passed to `find_layout`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m         )\n\u001b[1;32m--> 506\u001b[0m     \u001b[39mreturn\u001b[39;00m make_eeg_layout(info, exclude\u001b[39m=\u001b[39;49mexclude)\n\u001b[0;32m    507\u001b[0m \u001b[39melif\u001b[39;00m has_csd_coils \u001b[39mand\u001b[39;00m ch_type \u001b[39min\u001b[39;00m [\u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mcsd\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    508\u001b[0m     \u001b[39mreturn\u001b[39;00m make_eeg_layout(info, exclude\u001b[39m=\u001b[39mexclude, csd\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\20121\\OneDrive\\Desktop\\Optimized-BCI\\.venv\\lib\\site-packages\\mne\\channels\\layout.py:326\u001b[0m, in \u001b[0;36mmake_eeg_layout\u001b[1;34m(info, radius, width, height, exclude, csd)\u001b[0m\n\u001b[0;32m    324\u001b[0m     pick_kwargs\u001b[39m.\u001b[39mupdate(csd\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, eeg\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    325\u001b[0m picks \u001b[39m=\u001b[39m pick_types(info, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpick_kwargs)\n\u001b[1;32m--> 326\u001b[0m loc2d \u001b[39m=\u001b[39m _find_topomap_coords(info, picks)\n\u001b[0;32m    327\u001b[0m names \u001b[39m=\u001b[39m [info[\u001b[39m\"\u001b[39m\u001b[39mchs\u001b[39m\u001b[39m\"\u001b[39m][i][\u001b[39m\"\u001b[39m\u001b[39mch_name\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m picks]\n\u001b[0;32m    329\u001b[0m \u001b[39m# Scale [x, y] to be in the range [-0.5, 0.5]\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[39m# Don't mess with the origin or aspect ratio\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\20121\\OneDrive\\Desktop\\Optimized-BCI\\.venv\\lib\\site-packages\\mne\\channels\\layout.py:738\u001b[0m, in \u001b[0;36m_find_topomap_coords\u001b[1;34m(info, picks, layout, ignore_overlap, to_sphere, sphere)\u001b[0m\n\u001b[0;32m    736\u001b[0m     pos \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(pos)\n\u001b[0;32m    737\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 738\u001b[0m     pos \u001b[39m=\u001b[39m _auto_topomap_coords(\n\u001b[0;32m    739\u001b[0m         info,\n\u001b[0;32m    740\u001b[0m         picks,\n\u001b[0;32m    741\u001b[0m         ignore_overlap\u001b[39m=\u001b[39;49mignore_overlap,\n\u001b[0;32m    742\u001b[0m         to_sphere\u001b[39m=\u001b[39;49mto_sphere,\n\u001b[0;32m    743\u001b[0m         sphere\u001b[39m=\u001b[39;49msphere,\n\u001b[0;32m    744\u001b[0m     )\n\u001b[0;32m    746\u001b[0m \u001b[39mreturn\u001b[39;00m pos\n",
      "File \u001b[1;32mc:\\Users\\20121\\OneDrive\\Desktop\\Optimized-BCI\\.venv\\lib\\site-packages\\mne\\channels\\layout.py:813\u001b[0m, in \u001b[0;36m_auto_topomap_coords\u001b[1;34m(info, picks, ignore_overlap, to_sphere, sphere)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[39m# Get EEG digitization points\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[39mif\u001b[39;00m info[\u001b[39m\"\u001b[39m\u001b[39mdig\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(info[\u001b[39m\"\u001b[39m\u001b[39mdig\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 813\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo digitization points found.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    815\u001b[0m locs3d \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\n\u001b[0;32m    816\u001b[0m     [\n\u001b[0;32m    817\u001b[0m         point[\u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m     ]\n\u001b[0;32m    821\u001b[0m )\n\u001b[0;32m    823\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(locs3d) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No digitization points found."
     ]
    }
   ],
   "source": [
    "\"\"\"code from the mne documentation\n",
    "https://mne.tools/dev/auto_examples/decoding/plot_decoding_csp_eeg.html\"\"\"\n",
    "\n",
    "#this is the MLP neural net classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "for f in fp:\n",
    "    raw = creatRawArray(fp[f])\n",
    "    events, labels = creatEventsArray(fp[f])    \n",
    "    \n",
    "    # Apply band-pass filter\n",
    "    raw.filter(low_freq, high_freq, fir_design='firwin', skip_by_annotation='edge')\n",
    "    \n",
    "\n",
    "    # event_train = eventsTrain(fp[f])\n",
    "    epochs = mne.Epochs(raw, events=events, event_id=event_id, tmin=tmin, tmax=tmax, baseline=None, preload=True,\n",
    "                        verbose=False)#, picks=picks)\n",
    "\n",
    "    epochs_train = epochs.copy().crop(tmin=1., tmax=2.)\n",
    "    labels = epochs.events[:, -1] - 2\n",
    "\n",
    "    # Define a monte-carlo cross-validation generator (reduce variance):\n",
    "    scores = []\n",
    "    epochs_data = epochs.get_data()\n",
    "    epochs_data_train = epochs_train.get_data()\n",
    "    \n",
    "    #shuffling the data\n",
    "    cv = ShuffleSplit(5, test_size=0.2, random_state=42)\n",
    "    cv_split = cv.split(epochs_data_train)\n",
    "    \n",
    "    #splitting the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(epochs_data_train, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Assemble a classifier\n",
    "    MLP_C = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(16, 16), random_state=42)\n",
    "    csp = CSP(n_components=len(epochs.ch_names), reg=None, log=True, norm_trace=False)\n",
    "   \n",
    "    # Use scikit-learn Pipeline with cross_val_score function\n",
    "    clf = Pipeline([('CSP', csp), ('MLP_C', MLP_C)])\n",
    "    scores = cross_val_score(clf, epochs_data_train, labels, cv=cv, n_jobs=1)\n",
    "    \n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "    y_train_copy = y_train.copy()\n",
    "    \n",
    "    print(y_train)\n",
    "    for i in range(len(y_train)):\n",
    "        if -1 == y_train[i]:\n",
    "            y_train_copy[i] = 0\n",
    "        else:\n",
    "            y_train_copy[i] = 1\n",
    "    \n",
    "    \n",
    "    clf.fit(X_train, y_train_copy)\n",
    "    pred = clf.predict(X_test)\n",
    "    rmse_train = float(format(np.sqrt(metrics.mean_squared_error(clf.predict(X_train), y_train_copy)),'.3f'))\n",
    "    print(\"rmse_train:\",rmse_train)\n",
    "    r2_train = float(format(clf.score(X_train, y_train_copy),'.3f'))\n",
    "    print(\"r2_train:\",r2_train)\n",
    "    # ar2_train = float(format(adjustedR2(clf.score(X_train, y_train),X_train.shape[0],3),'.3f'))\n",
    "    mae_train=float(format((metrics.mean_absolute_error(clf.predict(X_train), y_train_copy)),'.3f'))\n",
    "    print(\"mae_train:\",mae_train)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    y_test_copy = y_test.copy()\n",
    "    \n",
    "    print(y_test)\n",
    "    for i in range(len(y_test)):\n",
    "        if -1 == y_test[i]:\n",
    "            y_test_copy[i] = 0\n",
    "        else:\n",
    "            y_test_copy[i] = 1\n",
    "    print(y_test_copy)\n",
    "    print('__________________________________________________________________________________')\n",
    "    \n",
    "    \n",
    "    \n",
    "    rmse_test = float(format(np.sqrt(metrics.mean_squared_error(clf.predict(X_test), y_test_copy)),'.3f'))\n",
    "    print(\"rmse_test:\",rmse_test)\n",
    "    r2_test = float(format(clf.score(X_test, y_test_copy),'.3f'))\n",
    "    print(\"r2_test:\",r2_test)\n",
    "    # ar2_test = float(format(adjustedR2(clf.score(X_test, y_test),X_test.shape[0],3),'.3f'))\n",
    "    mae_test=float(format((metrics.mean_absolute_error(clf.predict(X_test), y_test_copy)),'.3f'))\n",
    "    print(\"mae_test:\",mae_test)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    cv_train = float(format(cross_val_score(clf,X_train, y_train_copy,cv=5).mean(),'.3f'))\n",
    "    print(\"cv_train:\",cv_train)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    cv_test = float(format(cross_val_score(clf,X_test, y_test_copy,cv=5).mean(),'.3f'))\n",
    "    print(\"cv_test:\",cv_test)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "\n",
    "    # Printing the results\n",
    "    class_balance = np.mean(labels == labels[0])\n",
    "    class_balance = max(class_balance, 1. - class_balance)\n",
    "    print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores), class_balance))\n",
    "    \n",
    "    #making the labels more generalized\n",
    "    \n",
    "    print('__________________________________________________________________________________')\n",
    "    print(pred)\n",
    "    \n",
    "    #confusion matrix to know which class is being predicted\n",
    "    print('__________________________________________________________________________')\n",
    "    print('confusion matrix: ', confusion_matrix(y_test_copy, pred))\n",
    "    print('__________________________________________________________________________')\n",
    "\n",
    "#     print(\"precision_score\",precision_score(pred, y_test_copy))\n",
    "    print(\"precision_score\",precision_score(y_test_copy, pred))\n",
    "#     print(\"recall_score\",recall_score(pred, y_test_copy))\n",
    "    print(\"recall_score\",recall_score(y_test_copy, pred))\n",
    "\n",
    "#     print(\"f1_score\",f1_score(pred, y_test_copy))\n",
    "    print(\"f1_score\",f1_score(y_test_copy, pred))\n",
    "    \n",
    "    \n",
    "    #new territory from here\n",
    "    y_probas = cross_val_predict(clf, X_test, y_test_copy, cv=5, method='predict_proba')\n",
    "    \n",
    "    y_test_dfs = y_probas[:, 1]\n",
    "\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test_copy, y_test_dfs)\n",
    "    #precisions, recalls, thresholds = precision_recall_curve(y_test_copy, pred)\n",
    "\n",
    "    print('precisions', precisions)\n",
    "    precisions.sort()\n",
    "    print('precisions1 -', precisions[-1])\n",
    "    print('precisions0 - ', precisions[0])\n",
    "    print('precisions', precisions.size)\n",
    "    print('recalls', recalls)\n",
    "    recalls.sort()\n",
    "    print('recalls1 -', recalls[-1])\n",
    "    print('recalls0 -', recalls[0])\n",
    "    print('recalls', recalls.size)\n",
    "    print('thresholds', thresholds)\n",
    "    thresholds.sort()\n",
    "    print('thresholds1 -', thresholds[-1])\n",
    "    print('thresholds0 -', thresholds[0])\n",
    "    print('thresholds', thresholds.size)\n",
    "    \n",
    "    #threshold precision recall graph\n",
    "    recall_90_precision = recalls[np.argmax(precisions >= 0.90)]\n",
    "    print(recall_90_precision)\n",
    "    threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)-1]\n",
    "    print(threshold_90_precision)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plot_precision_vs_recall(precisions, recalls)\n",
    "    plt.plot([recall_90_precision, recall_90_precision], [0., 0.9], \"r:\")\n",
    "    plt.plot([0.0, recall_90_precision], [0.9, 0.9], \"r:\")\n",
    "    plt.plot([recall_90_precision], [0.9], \"ro\")\n",
    "    fig_name = \"MLP_neural_net_precision_vs_recall_\"+ f\n",
    "    save_fig(fig_name)\n",
    "    plt.show()\n",
    "    \n",
    "    #ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_copy, y_test_dfs)\n",
    "   \n",
    "\n",
    "    \n",
    "    #plot curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plot_roc_curve(fpr, tpr)\n",
    "    fpr_90 = fpr[np.argmax( tpr >= recall_90_precision)]\n",
    "    plt.plot([fpr_90, fpr_90], [0., recall_90_precision], \"r:\")\n",
    "    plt.plot([0.0, fpr_90], [recall_90_precision, recall_90_precision], \"r:\")\n",
    "    plt.plot([fpr_90], [recall_90_precision], \"ro\")\n",
    "    fig_name = \"MLP_neural_net_roc_curve_\"+ f\n",
    "    save_fig(fig_name)\n",
    "    plt.show()\n",
    "    \n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    print('This is the roc_auc_score', roc_auc_score(pred, y_test_dfs))\n",
    "    #roc_auc_score(y_test_copy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
