{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import butter,filtfilt\n",
    "import scipy.signal as sg\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "from scipy.fftpack import fft, ifft\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "py.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import scikitplot as skplt\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessors\n",
    "\n",
    "import scipy.io as sio\n",
    "\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "\n",
    "from mne import Epochs, pick_types, events_from_annotations\n",
    "from mne.channels import make_standard_montage\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.decoding import CSP\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def inputmat(fp):\n",
    "    \"\"\"load .mat file and return m as a dict\"\"\"\n",
    "    mat = sio.loadmat(fp, squeeze_me=True)\n",
    "    td = {}  # create a dict\n",
    "\n",
    "    # Numpy array of size channel_num * points.\n",
    "    td['data'] = mat['cnt'].T  # data\n",
    "    td['freq'] = mat['nfo']['fs'][True][0]  # Sampling frequency\n",
    "\n",
    "    # channel names are necessary information for creating a rawArray.\n",
    "    td['ch_names'] = mat['nfo']['clab'][True][0]\n",
    "\n",
    "    # Position of channels\n",
    "    \n",
    "    td['electrode_x'] = mat['nfo']['xpos'][True][0]\n",
    "    td['electrode_y'] = mat['nfo']['ypos'][True][0]\n",
    "\n",
    "    #make trials by finding trials and its data\n",
    "    td['cue'] = mat['mrk']['pos'][True][0] #time of cue\n",
    "    td['labels'] = mat['mrk']['y'][True][0] #labels of the data\n",
    "    return td\n",
    "\n",
    "\n",
    "def creatEventsArray(fp):\n",
    "    \"\"\"Create events array. The second column default to zero.\"\"\"\n",
    "    td = inputmat(fp)\n",
    "    events = np.zeros((td['labels'].size, 3), int) #here we have made a matrix type array of the size of label.size*3\n",
    "#     print(events)\n",
    "    events[:, 0] = td['cue']  # The first column is the sample number of the event.\n",
    "#     print(events[:, 0])\n",
    "    events[:, 2] = td['labels']  # The third column is the new event value.\n",
    "#     print(events[:, 2])\n",
    "    return events, td['labels']\n",
    "\n",
    "\n",
    "def creatRawArray(fp):\n",
    "    \"\"\"Create a mne.io.RawArray object, data: array, shape (n_channels, n_times)\"\"\"\n",
    "    td = inputmat(fp)\n",
    "    ch_names = td['ch_names'].tolist()\n",
    "    info = mne.create_info(ch_names, td['freq'], 'eeg')  # Create info for raw\n",
    "    raw = mne.io.RawArray(td['data'], info, first_samp=0, copy='auto', verbose=None)\n",
    "    return raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to save the figures\n",
    "\n",
    "\"\"\"\n",
    "image relation with dpi and resolution\n",
    "\n",
    "https://stackoverflow.com/questions/47633546/relationship-between-dpi-and-figure-size\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"classification_png_ex\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=660):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from mne.decoding import CSP\n",
    "from mne.channels import read_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The files c, d, e are the artificial data so we can test out our labels in different ways in them\"\"\"\n",
    "\n",
    "\n",
    "file1 = r'Data/BCICIV_1calib_1000Hz_mat/BCICIV_calib_ds1a_1000Hz.mat'\n",
    "file2 = r'Data/BCICIV_1calib_1000Hz_mat/BCICIV_calib_ds1b_1000Hz.mat'\n",
    "\n",
    "# artificial data files\n",
    "\n",
    "file3 = r'Data/BCICIV_1calib_1000Hz_mat/BCICIV_calib_ds1c_1000Hz.mat'\n",
    "file4 = r'Data/BCICIV_1calib_1000Hz_mat/BCICIV_calib_ds1d_1000Hz.mat'\n",
    "file5 = r'Data/BCICIV_1calib_1000Hz_mat/BCICIV_calib_ds1e_1000Hz.mat'\n",
    "file6 = r'Data/BCICIV_1calib_1000Hz_mat/BCICIV_calib_ds1f_1000Hz.mat'\n",
    "file7 = r'Data/BCICIV_1calib_1000Hz_mat/BCICIV_calib_ds1g_1000Hz.mat'\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"making the file dictionary and channel dictionary for easy pickup\"\"\"\n",
    "fp = {\n",
    "    'ds1a': file1,\n",
    "    'ds1b': file2,\n",
    "    'ds1f': file6,\n",
    "    'ds1g': file7,\n",
    "}\n",
    "\n",
    "\n",
    "#     'ds1c': file3, #these three are artificial datatsets\n",
    "#     'ds1d': file4,\n",
    "#     'ds1e': file5,\n",
    "\n",
    "\"\"\" Pick channels if necessary but not needed as we will be deploying a CSP pipeline ahead\"\"\"\n",
    "\n",
    "# pick_chan = {\n",
    "#     'ds1a': ['C3', 'Cz', 'C5'],\n",
    "#     'ds1b': ['C3', 'Cz', 'C5'],\n",
    "#     'ds1c': ['C3', 'Cz', 'C5'],  \n",
    "#     'ds1d': ['C3', 'Cz', 'C5'],\n",
    "#     'ds1e': ['C3', 'Cz', 'C5'],\n",
    "#     'ds1f': ['C3', 'Cz', 'C5'],\n",
    "#     'ds1g': ['C3', 'Cz', 'C5'],\n",
    "# }\n",
    "\n",
    "low_freq, high_freq = 7., 30.\n",
    "tmin, tmax = 0., 3.5\n",
    "\n",
    "# event_id\n",
    "# event_id = {'right': 1, 'foot': 2}\n",
    "#changing eventid from right to left\n",
    "event_id = {'left': -1, 'foot': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjustedR2(r2,n,k=3):\n",
    "    return r2-(k-1)/(n-k)*(1-r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
    "    plt.legend(loc=\"center right\", fontsize=16) \n",
    "    plt.xlabel(\"Threshold\", fontsize=16)        \n",
    "    plt.grid(True)                              \n",
    "    plt.axis([-50, 150, 0, 1])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('Flase positive Rate (Fall-out)', Fontsize=16)\n",
    "    plt.ylabel('True positive Rate (Recall)', Fontsize=16)\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_vs_recall(precisions, recalls):\n",
    "    plt.plot(recalls, precisions, \"b-\", linewidth=2)\n",
    "    plt.xlabel(\"Recall\", fontsize=16)\n",
    "    plt.ylabel(\"Precision\", fontsize=16)\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"code from the mne documentation\n",
    "https://mne.tools/dev/auto_examples/decoding/plot_decoding_csp_eeg.html\n",
    "This is the LDA classifier pipeline\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "for f in fp:\n",
    "    raw = creatRawArray(fp[f])\n",
    "    events, labels = creatEventsArray(fp[f])\n",
    "    \n",
    "    print('__________________________________________________________________________')\n",
    "    print('labels: ', labels)\n",
    "    print('__________________________________________________________________________')\n",
    "    \n",
    "    # Apply band-pass filter\n",
    "    raw.filter(low_freq, high_freq, fir_design='firwin', skip_by_annotation='edge')\n",
    "\n",
    "    # event_train = eventsTrain(fp[f])\n",
    "    epochs = mne.Epochs(raw, events=events, event_id=event_id, tmin=tmin, tmax=tmax, baseline=None, preload=True,\n",
    "                        verbose=False)\n",
    "\n",
    "    epochs_train = epochs.copy().crop(tmin=1., tmax=2.)\n",
    "    print('__________________________________________________________________________')\n",
    "    print('labels after band pass filter: ', labels)\n",
    "    print('__________________________________________________________________________')\n",
    "\n",
    "    # labels = epochs.events[:, -1] - 2\n",
    "    labels = epochs.events[:, -1]\n",
    "\n",
    "\n",
    "    print('__________________________________________________________________________')\n",
    "    print('labels after epochs.events change: ', labels)\n",
    "    print('__________________________________________________________________________')\n",
    "\n",
    "    # Define a monte-carlo cross-validation generator (reduce variance):\n",
    "    scores = []\n",
    "    epochs_data = epochs.get_data()\n",
    "    epochs_data_train = epochs_train.get_data()\n",
    "    cv = ShuffleSplit(5, test_size=0.2, random_state=42)\n",
    "    cv_split = cv.split(epochs_data_train)\n",
    "    \n",
    "    \n",
    "    #splitting the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(epochs_data_train, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Assemble a classifier\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    csp = CSP(n_components=len(epochs.ch_names), reg=None, log=True, norm_trace=False)\n",
    "\n",
    "    # Use scikit-learn Pipeline with cross_val_score function\n",
    "    clf = Pipeline([('CSP', csp), ('LDA', lda)])\n",
    "    scores = cross_val_score(clf, epochs_data_train, labels, cv=cv, n_jobs=1)\n",
    "    \n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "    y_train_copy = y_train.copy()\n",
    "    \n",
    "    print(y_train)\n",
    "    for i in range(len(y_train)):\n",
    "        if -1 == y_train[i]:\n",
    "            y_train_copy[i] = 0\n",
    "        else:\n",
    "            y_train_copy[i] = 1\n",
    "    \n",
    "    \n",
    "    clf.fit(X_train, y_train_copy)\n",
    "    pred = clf.predict(X_test)\n",
    "    rmse_train = float(format(np.sqrt(metrics.mean_squared_error(clf.predict(X_train), y_train_copy)),'.3f'))\n",
    "    print(\"rmse_train:\",rmse_train)\n",
    "    r2_train = float(format(clf.score(X_train, y_train_copy),'.3f'))\n",
    "    print(\"r2_train:\",r2_train)\n",
    "    # ar2_train = float(format(adjustedR2(clf.score(X_train, y_train),X_train.shape[0],3),'.3f'))\n",
    "    mae_train=float(format((metrics.mean_absolute_error(clf.predict(X_train), y_train_copy)),'.3f'))\n",
    "    print(\"mae_train:\",mae_train)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    y_test_copy = y_test.copy()\n",
    "    \n",
    "    print(y_test)\n",
    "    for i in range(len(y_test)):\n",
    "        if -1 == y_test[i]:\n",
    "            y_test_copy[i] = 0\n",
    "        else:\n",
    "            y_test_copy[i] = 1\n",
    "    print(y_test_copy)\n",
    "    print('__________________________________________________________________________________')\n",
    "    \n",
    "    \n",
    "    \n",
    "    rmse_test = float(format(np.sqrt(metrics.mean_squared_error(clf.predict(X_test), y_test_copy)),'.3f'))\n",
    "    print(\"rmse_test:\",rmse_test)\n",
    "    r2_test = float(format(clf.score(X_test, y_test_copy),'.3f'))\n",
    "    print(\"r2_test:\",r2_test)\n",
    "    # ar2_test = float(format(adjustedR2(clf.score(X_test, y_test),X_test.shape[0],3),'.3f'))\n",
    "    mae_test=float(format((metrics.mean_absolute_error(clf.predict(X_test), y_test_copy)),'.3f'))\n",
    "    print(\"mae_test:\",mae_test)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    cv_train = float(format(cross_val_score(clf,X_train, y_train_copy,cv=5).mean(),'.3f'))\n",
    "    print(\"cv_train:\",cv_train)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    cv_test = float(format(cross_val_score(clf,X_test, y_test_copy,cv=5).mean(),'.3f'))\n",
    "    print(\"cv_test:\",cv_test)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "\n",
    "    # Printing the results\n",
    "    class_balance = np.mean(labels == labels[0])\n",
    "    class_balance = max(class_balance, 1. - class_balance)\n",
    "    print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores), class_balance))\n",
    "    \n",
    "    #making the labels more generalized\n",
    "    \n",
    "    print('__________________________________________________________________________________')\n",
    "    print(pred)\n",
    "\n",
    "    \n",
    "    #confusion matrix to know which class is being predicted\n",
    "    print('__________________________________________________________________________')\n",
    "    print('confusion matrix: ', confusion_matrix(y_test_copy, pred))\n",
    "    print('__________________________________________________________________________')\n",
    "    \n",
    "#     print(\"precision_score\",precision_score(pred, y_test_copy))\n",
    "    print(\"precision_score\",precision_score(y_test_copy, pred))\n",
    "#     print(\"recall_score\",recall_score(pred, y_test_copy))\n",
    "    print(\"recall_score\",recall_score(y_test_copy, pred))\n",
    "\n",
    "#     print(\"f1_score\",f1_score(pred, y_test_copy))\n",
    "    print(\"f1_score\",f1_score(y_test_copy, pred))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #new territory from here\n",
    "    y_test_dfs = cross_val_predict(clf, X_test, y_test_copy, cv=5, method='decision_function')\n",
    "\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test_copy, y_test_dfs)\n",
    "    #precisions, recalls, thresholds = precision_recall_curve(y_test_copy, pred)\n",
    "\n",
    "    print('precisions', precisions)\n",
    "    precisions.sort()\n",
    "    print('precisions1 -', precisions[-1])\n",
    "    print('precisions0 - ', precisions[0])\n",
    "    print('precisions', precisions.size)\n",
    "    print('recalls', recalls)\n",
    "    recalls.sort()\n",
    "    print('recalls1 -', recalls[-1])\n",
    "    print('recalls0 -', recalls[0])\n",
    "    print('recalls', recalls.size)\n",
    "    print('thresholds', thresholds)\n",
    "    thresholds.sort()\n",
    "    print('thresholds1 -', thresholds[-1])\n",
    "    print('thresholds0 -', thresholds[0])\n",
    "    print('thresholds', thresholds.size)\n",
    "    \n",
    "    #threshold precision recall graph\n",
    "    recall_90_precision = recalls[np.argmax(precisions >= 0.90)]\n",
    "    print(recall_90_precision)\n",
    "    threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)-1]\n",
    "    print(threshold_90_precision)\n",
    "\n",
    "\n",
    "#     plt.figure(figsize=(8, 4))                                                                  \n",
    "#     plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "#     plt.plot([threshold_90_precision, threshold_90_precision], [0., 0.9], \"r:\")                 \n",
    "#     plt.plot([-50, threshold_90_precision], [0.9, 0.9], \"r:\")                                \n",
    "#     plt.plot([-50, threshold_90_precision], [recall_90_precision, recall_90_precision], \"r:\")\n",
    "#     plt.plot([threshold_90_precision], [0.9], \"ro\")                                           \n",
    "#     plt.plot([threshold_90_precision], [recall_90_precision], \"ro\")                           \n",
    "#     plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plot_precision_vs_recall(precisions, recalls)\n",
    "    plt.plot([recall_90_precision, recall_90_precision], [0., 0.9], \"r:\")\n",
    "    plt.plot([0.0, recall_90_precision], [0.9, 0.9], \"r:\")\n",
    "    plt.plot([recall_90_precision], [0.9], \"ro\")\n",
    "    fig_name = \"LDA_classifier_precision_vs_recall_\"+ f\n",
    "    save_fig(fig_name)\n",
    "    plt.show()\n",
    "    \n",
    "    #ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_copy, y_test_dfs)\n",
    "    #fpr, tpr, thresholds = roc_curve(y_test_copy, pred)\n",
    "\n",
    "    \n",
    "    #plot curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plot_roc_curve(fpr, tpr)\n",
    "    fpr_90 = fpr[np.argmax( tpr >= recall_90_precision)]\n",
    "    plt.plot([fpr_90, fpr_90], [0., recall_90_precision], \"r:\")\n",
    "    plt.plot([0.0, fpr_90], [recall_90_precision, recall_90_precision], \"r:\")\n",
    "    plt.plot([fpr_90], [recall_90_precision], \"ro\")\n",
    "    fig_name = \"LDA_classifier_roc_curve_\"+ f\n",
    "    save_fig(fig_name)\n",
    "    plt.show()\n",
    "    \n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    print('This is the roc_auc_score', roc_auc_score(pred, y_test_dfs))\n",
    "    #roc_auc_score(y_test_copy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"code from the mne documentation\n",
    "https://mne.tools/dev/auto_examples/decoding/plot_decoding_csp_eeg.html\"\"\"\n",
    "\n",
    "#this is the SVM classifier\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from mne.decoding import Scaler\n",
    "\n",
    "for f in fp:\n",
    "    raw = creatRawArray(fp[f])\n",
    "    events, labels = creatEventsArray(fp[f])\n",
    "    \n",
    "    \n",
    "    # Apply band-pass filter\n",
    "    raw.filter(low_freq, high_freq, fir_design='firwin', skip_by_annotation='edge')\n",
    "    \n",
    "\n",
    "    epochs = mne.Epochs(raw, events=events, event_id=event_id, tmin=tmin, tmax=tmax, baseline=None, preload=True,\n",
    "                        verbose=False)#, picks=picks)\n",
    "\n",
    "    epochs_train = epochs.copy().crop(tmin=1., tmax=2.)\n",
    "    labels = epochs.events[:, -1] - 2\n",
    "\n",
    "    # Define a monte-carlo cross-validation generator (reduce variance):\n",
    "    scores = []\n",
    "    epochs_data = epochs.get_data()\n",
    "    epochs_data_train = epochs_train.get_data()\n",
    "    \n",
    "    #shuffling the data\n",
    "    cv = ShuffleSplit(5, test_size=0.2, random_state=42)\n",
    "    cv_split = cv.split(epochs_data_train)\n",
    "    \n",
    "    #splitting the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(epochs_data_train, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Assemble a classifier\n",
    "    SVM_C = svm.SVC(kernel='rbf', degree=100)\n",
    "    csp = CSP(n_components=len(epochs.ch_names), reg=None, log=True, norm_trace=False)\n",
    "\n",
    "    # Use scikit-learn Pipeline with cross_val_score function\n",
    "    clf = Pipeline([('CSP', csp), ('SVM_C', SVM_C)])\n",
    "    scores = cross_val_score(clf, epochs_data_train, labels, cv=cv, n_jobs=1)\n",
    "    \n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "    y_train_copy = y_train.copy()\n",
    "    \n",
    "    print(y_train)\n",
    "    for i in range(len(y_train)):\n",
    "        if -1 == y_train[i]:\n",
    "            y_train_copy[i] = 0\n",
    "        else:\n",
    "            y_train_copy[i] = 1\n",
    "    \n",
    "    \n",
    "    clf.fit(X_train, y_train_copy)\n",
    "    pred = clf.predict(X_test)\n",
    "    rmse_train = float(format(np.sqrt(metrics.mean_squared_error(clf.predict(X_train), y_train_copy)),'.3f'))\n",
    "    print(\"rmse_train:\",rmse_train)\n",
    "    r2_train = float(format(clf.score(X_train, y_train_copy),'.3f'))\n",
    "    print(\"r2_train:\",r2_train)\n",
    "    # ar2_train = float(format(adjustedR2(clf.score(X_train, y_train),X_train.shape[0],3),'.3f'))\n",
    "    mae_train=float(format((metrics.mean_absolute_error(clf.predict(X_train), y_train_copy)),'.3f'))\n",
    "    print(\"mae_train:\",mae_train)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    y_test_copy = y_test.copy()\n",
    "    \n",
    "    print(y_test)\n",
    "    for i in range(len(y_test)):\n",
    "        if -1 == y_test[i]:\n",
    "            y_test_copy[i] = 0\n",
    "        else:\n",
    "            y_test_copy[i] = 1\n",
    "    print(y_test_copy)\n",
    "    print('__________________________________________________________________________________')\n",
    "    \n",
    "    \n",
    "    \n",
    "    rmse_test = float(format(np.sqrt(metrics.mean_squared_error(clf.predict(X_test), y_test_copy)),'.3f'))\n",
    "    print(\"rmse_test:\",rmse_test)\n",
    "    r2_test = float(format(clf.score(X_test, y_test_copy),'.3f'))\n",
    "    print(\"r2_test:\",r2_test)\n",
    "    # ar2_test = float(format(adjustedR2(clf.score(X_test, y_test),X_test.shape[0],3),'.3f'))\n",
    "    mae_test=float(format((metrics.mean_absolute_error(clf.predict(X_test), y_test_copy)),'.3f'))\n",
    "    print(\"mae_test:\",mae_test)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    cv_train = float(format(cross_val_score(clf,X_train, y_train_copy,cv=5).mean(),'.3f'))\n",
    "    print(\"cv_train:\",cv_train)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    cv_test = float(format(cross_val_score(clf,X_test, y_test_copy,cv=5).mean(),'.3f'))\n",
    "    print(\"cv_test:\",cv_test)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "\n",
    "    # Printing the results\n",
    "    class_balance = np.mean(labels == labels[0])\n",
    "    class_balance = max(class_balance, 1. - class_balance)\n",
    "    print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores), class_balance))\n",
    "    \n",
    "    #making the labels more generalized\n",
    "    \n",
    "    print('__________________________________________________________________________________')\n",
    "    print(pred)\n",
    "    \n",
    "    #confusion matrix to know which class is being predicted\n",
    "    print('__________________________________________________________________________')\n",
    "    print('confusion matrix: ', confusion_matrix(y_test_copy, pred))\n",
    "    print('__________________________________________________________________________')\n",
    "\n",
    "#     print(\"precision_score\",precision_score(pred, y_test_copy))\n",
    "    print(\"precision_score\",precision_score(y_test_copy, pred))\n",
    "#     print(\"recall_score\",recall_score(pred, y_test_copy))\n",
    "    print(\"recall_score\",recall_score(y_test_copy, pred))\n",
    "\n",
    "#     print(\"f1_score\",f1_score(pred, y_test_copy))\n",
    "    print(\"f1_score\",f1_score(y_test_copy, pred))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #new territory from here\n",
    "    y_test_dfs = cross_val_predict(clf, X_test, y_test_copy, cv=5, method='decision_function')\n",
    "\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test_copy, y_test_dfs)\n",
    "    #precisions, recalls, thresholds = precision_recall_curve(y_test_copy, pred)\n",
    "\n",
    "    print('precisions', precisions)\n",
    "    precisions.sort()\n",
    "    print('precisions1 -', precisions[-1])\n",
    "    print('precisions0 - ', precisions[0])\n",
    "    print('precisions', precisions.size)\n",
    "    print('recalls', recalls)\n",
    "    recalls.sort()\n",
    "    print('recalls1 -', recalls[-1])\n",
    "    print('recalls0 -', recalls[0])\n",
    "    print('recalls', recalls.size)\n",
    "    print('thresholds', thresholds)\n",
    "    thresholds.sort()\n",
    "    print('thresholds1 -', thresholds[-1])\n",
    "    print('thresholds0 -', thresholds[0])\n",
    "    print('thresholds', thresholds.size)\n",
    "    \n",
    "    #threshold precision recall graph\n",
    "    recall_90_precision = recalls[np.argmax(precisions >= 0.90)]\n",
    "    print(recall_90_precision)\n",
    "    threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)-1]\n",
    "    print(threshold_90_precision)\n",
    "\n",
    "\n",
    "#     plt.figure(figsize=(8, 4))                                                                  \n",
    "#     plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "#     plt.plot([threshold_90_precision, threshold_90_precision], [0., 0.9], \"r:\")                 \n",
    "#     plt.plot([-50, threshold_90_precision], [0.9, 0.9], \"r:\")                                \n",
    "#     plt.plot([-50, threshold_90_precision], [recall_90_precision, recall_90_precision], \"r:\")\n",
    "#     plt.plot([threshold_90_precision], [0.9], \"ro\")                                           \n",
    "#     plt.plot([threshold_90_precision], [recall_90_precision], \"ro\")                           \n",
    "#     plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plot_precision_vs_recall(precisions, recalls)\n",
    "    plt.plot([recall_90_precision, recall_90_precision], [0., 0.9], \"r:\")\n",
    "    plt.plot([0.0, recall_90_precision], [0.9, 0.9], \"r:\")\n",
    "    plt.plot([recall_90_precision], [0.9], \"ro\")\n",
    "    fig_name = \"SVM_classifier_precision_vs_recall_\"+ f\n",
    "    save_fig(fig_name)\n",
    "    plt.show()\n",
    "    \n",
    "    #ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_copy, y_test_dfs)\n",
    "    #fpr, tpr, thresholds = roc_curve(y_test_copy, pred)\n",
    "\n",
    "    \n",
    "    #plot curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plot_roc_curve(fpr, tpr)\n",
    "    fpr_90 = fpr[np.argmax( tpr >= recall_90_precision)]\n",
    "    plt.plot([fpr_90, fpr_90], [0., recall_90_precision], \"r:\")\n",
    "    plt.plot([0.0, fpr_90], [recall_90_precision, recall_90_precision], \"r:\")\n",
    "    plt.plot([fpr_90], [recall_90_precision], \"ro\")\n",
    "    fig_name = \"SVM_classifier_roc_curve_\"+ f\n",
    "    save_fig(fig_name)\n",
    "    plt.show()\n",
    "    \n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    print('This is the roc_auc_score', roc_auc_score(pred, y_test_dfs))\n",
    "    #roc_auc_score(y_test_copy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"code from the mne documentation\n",
    "https://mne.tools/dev/auto_examples/decoding/plot_decoding_csp_eeg.html\"\"\"\n",
    "\n",
    "#this is the Random Forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "for f in fp:\n",
    "    raw = creatRawArray(fp[f])\n",
    "    events, labels = creatEventsArray(fp[f])\n",
    "    \n",
    "    \n",
    "    # Apply band-pass filter\n",
    "    raw.filter(low_freq, high_freq, fir_design='firwin', skip_by_annotation='edge')\n",
    " \n",
    "    epochs = mne.Epochs(raw, events=events, event_id=event_id, tmin=tmin, tmax=tmax, baseline=None, preload=True,\n",
    "                        verbose=False)#, picks=picks)\n",
    "\n",
    "    epochs_train = epochs.copy().crop(tmin=1., tmax=2.)\n",
    "    labels = epochs.events[:, -1] - 2\n",
    "\n",
    "    # Define a monte-carlo cross-validation generator (reduce variance):\n",
    "    scores = []\n",
    "    epochs_data = epochs.get_data()\n",
    "    epochs_data_train = epochs_train.get_data()\n",
    "    \n",
    "    #shuffling the data\n",
    "    cv = ShuffleSplit(5, test_size=0.2, random_state=42)\n",
    "    cv_split = cv.split(epochs_data_train)\n",
    "    \n",
    "    #splitting the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(epochs_data_train, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Assemble a classifier\n",
    "    RFC = RandomForestClassifier()\n",
    "    csp = CSP(n_components=len(epochs.ch_names), reg=None, log=True, norm_trace=False)\n",
    "\n",
    "    # Use scikit-learn Pipeline with cross_val_score function\n",
    "    clf = Pipeline([('CSP', csp), ('RFC', RFC)])\n",
    "    scores = cross_val_score(clf, epochs_data_train, labels, cv=cv, n_jobs=1)\n",
    "    \n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "    y_train_copy = y_train.copy()\n",
    "    \n",
    "    print(y_train)\n",
    "    for i in range(len(y_train)):\n",
    "        if -1 == y_train[i]:\n",
    "            y_train_copy[i] = 0\n",
    "        else:\n",
    "            y_train_copy[i] = 1\n",
    "    \n",
    "    \n",
    "    clf.fit(X_train, y_train_copy)\n",
    "    pred = clf.predict(X_test)\n",
    "    rmse_train = float(format(np.sqrt(metrics.mean_squared_error(clf.predict(X_train), y_train_copy)),'.3f'))\n",
    "    print(\"rmse_train:\",rmse_train)\n",
    "    r2_train = float(format(clf.score(X_train, y_train_copy),'.3f'))\n",
    "    print(\"r2_train:\",r2_train)\n",
    "    # ar2_train = float(format(adjustedR2(clf.score(X_train, y_train),X_train.shape[0],3),'.3f'))\n",
    "    mae_train=float(format((metrics.mean_absolute_error(clf.predict(X_train), y_train_copy)),'.3f'))\n",
    "    print(\"mae_train:\",mae_train)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    y_test_copy = y_test.copy()\n",
    "    \n",
    "    print(y_test)\n",
    "    for i in range(len(y_test)):\n",
    "        if -1 == y_test[i]:\n",
    "            y_test_copy[i] = 0\n",
    "        else:\n",
    "            y_test_copy[i] = 1\n",
    "    print(y_test_copy)\n",
    "    print('__________________________________________________________________________________')\n",
    "    \n",
    "    \n",
    "    \n",
    "    rmse_test = float(format(np.sqrt(metrics.mean_squared_error(clf.predict(X_test), y_test_copy)),'.3f'))\n",
    "    print(\"rmse_test:\",rmse_test)\n",
    "    r2_test = float(format(clf.score(X_test, y_test_copy),'.3f'))\n",
    "    print(\"r2_test:\",r2_test)\n",
    "    # ar2_test = float(format(adjustedR2(clf.score(X_test, y_test),X_test.shape[0],3),'.3f'))\n",
    "    mae_test=float(format((metrics.mean_absolute_error(clf.predict(X_test), y_test_copy)),'.3f'))\n",
    "    print(\"mae_test:\",mae_test)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    cv_train = float(format(cross_val_score(clf,X_train, y_train_copy,cv=5).mean(),'.3f'))\n",
    "    print(\"cv_train:\",cv_train)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    cv_test = float(format(cross_val_score(clf,X_test, y_test_copy,cv=5).mean(),'.3f'))\n",
    "    print(\"cv_test:\",cv_test)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "\n",
    "    # Printing the results\n",
    "    class_balance = np.mean(labels == labels[0])\n",
    "    class_balance = max(class_balance, 1. - class_balance)\n",
    "    print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores), class_balance))\n",
    "    \n",
    "    #making the labels more generalized\n",
    "    \n",
    "    print('__________________________________________________________________________________')\n",
    "    print(pred)\n",
    "    \n",
    "    #confusion matrix to know which class is being predicted\n",
    "    print('__________________________________________________________________________')\n",
    "    print('confusion matrix: ', confusion_matrix(y_test_copy, pred))\n",
    "    print('__________________________________________________________________________')\n",
    "\n",
    "#     print(\"precision_score\",precision_score(pred, y_test_copy))\n",
    "    print(\"precision_score\",precision_score(y_test_copy, pred))\n",
    "#     print(\"recall_score\",recall_score(pred, y_test_copy))\n",
    "    print(\"recall_score\",recall_score(y_test_copy, pred))\n",
    "\n",
    "#     print(\"f1_score\",f1_score(pred, y_test_copy))\n",
    "    print(\"f1_score\",f1_score(y_test_copy, pred))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #new territory from here\n",
    "    y_probas = cross_val_predict(clf, X_test, y_test_copy, cv=5, method='predict_proba')\n",
    "    \n",
    "    y_test_dfs = y_probas[:, 1]\n",
    "\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test_copy, y_test_dfs)\n",
    "    #precisions, recalls, thresholds = precision_recall_curve(y_test_copy, pred)\n",
    "\n",
    "    print('precisions', precisions)\n",
    "    precisions.sort()\n",
    "    print('precisions1 -', precisions[-1])\n",
    "    print('precisions0 - ', precisions[0])\n",
    "    print('precisions', precisions.size)\n",
    "    print('recalls', recalls)\n",
    "    recalls.sort()\n",
    "    print('recalls1 -', recalls[-1])\n",
    "    print('recalls0 -', recalls[0])\n",
    "    print('recalls', recalls.size)\n",
    "    print('thresholds', thresholds)\n",
    "    thresholds.sort()\n",
    "    print('thresholds1 -', thresholds[-1])\n",
    "    print('thresholds0 -', thresholds[0])\n",
    "    print('thresholds', thresholds.size)\n",
    "    \n",
    "    #threshold precision recall graph\n",
    "    recall_90_precision = recalls[np.argmax(precisions >= 0.90)]\n",
    "    print(recall_90_precision)\n",
    "    threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)-1]\n",
    "    print(threshold_90_precision)\n",
    "\n",
    "\n",
    "#     plt.figure(figsize=(8, 4))                                                                  \n",
    "#     plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "#     plt.plot([threshold_90_precision, threshold_90_precision], [0., 0.9], \"r:\")                 \n",
    "#     plt.plot([-50, threshold_90_precision], [0.9, 0.9], \"r:\")                                \n",
    "#     plt.plot([-50, threshold_90_precision], [recall_90_precision, recall_90_precision], \"r:\")\n",
    "#     plt.plot([threshold_90_precision], [0.9], \"ro\")                                           \n",
    "#     plt.plot([threshold_90_precision], [recall_90_precision], \"ro\")                           \n",
    "#     plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plot_precision_vs_recall(precisions, recalls)\n",
    "    plt.plot([recall_90_precision, recall_90_precision], [0., 0.9], \"r:\")\n",
    "    plt.plot([0.0, recall_90_precision], [0.9, 0.9], \"r:\")\n",
    "    plt.plot([recall_90_precision], [0.9], \"ro\")\n",
    "    fig_name = \"Random_forest_classifier_precision_vs_recall_\"+ f\n",
    "    save_fig(fig_name)\n",
    "    plt.show()\n",
    "    \n",
    "    #ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_copy, y_test_dfs)\n",
    "    #fpr, tpr, thresholds = roc_curve(y_test_copy, pred)\n",
    "\n",
    "    \n",
    "    #plot curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plot_roc_curve(fpr, tpr)\n",
    "    fpr_90 = fpr[np.argmax( tpr >= recall_90_precision)]\n",
    "    plt.plot([fpr_90, fpr_90], [0., recall_90_precision], \"r:\")\n",
    "    plt.plot([0.0, fpr_90], [recall_90_precision, recall_90_precision], \"r:\")\n",
    "    plt.plot([fpr_90], [recall_90_precision], \"ro\")\n",
    "    fig_name = \"Random_forest_classifier_roc_curve_\"+ f\n",
    "    save_fig(fig_name)\n",
    "    plt.show()\n",
    "    \n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    print('This is the roc_auc_score', roc_auc_score(pred, y_test_dfs))\n",
    "    #roc_auc_score(y_test_copy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"code from the mne documentation\n",
    "https://mne.tools/dev/auto_examples/decoding/plot_decoding_csp_eeg.html\"\"\"\n",
    "\n",
    "#this is the MLP neural net classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "for f in fp:\n",
    "    raw = creatRawArray(fp[f])\n",
    "    events, labels = creatEventsArray(fp[f])    \n",
    "    \n",
    "    # Apply band-pass filter\n",
    "    raw.filter(low_freq, high_freq, fir_design='firwin', skip_by_annotation='edge')\n",
    "    \n",
    "\n",
    "    # event_train = eventsTrain(fp[f])\n",
    "    epochs = mne.Epochs(raw, events=events, event_id=event_id, tmin=tmin, tmax=tmax, baseline=None, preload=True,\n",
    "                        verbose=False)#, picks=picks)\n",
    "\n",
    "    epochs_train = epochs.copy().crop(tmin=1., tmax=2.)\n",
    "    labels = epochs.events[:, -1] - 2\n",
    "\n",
    "    # Define a monte-carlo cross-validation generator (reduce variance):\n",
    "    scores = []\n",
    "    epochs_data = epochs.get_data()\n",
    "    epochs_data_train = epochs_train.get_data()\n",
    "    \n",
    "    #shuffling the data\n",
    "    cv = ShuffleSplit(5, test_size=0.2, random_state=42)\n",
    "    cv_split = cv.split(epochs_data_train)\n",
    "    \n",
    "    #splitting the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(epochs_data_train, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Assemble a classifier\n",
    "    MLP_C = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(16, 16), random_state=42)\n",
    "    csp = CSP(n_components=len(epochs.ch_names), reg=None, log=True, norm_trace=False)\n",
    "\n",
    "    # Use scikit-learn Pipeline with cross_val_score function\n",
    "    clf = Pipeline([('CSP', csp), ('MLP_C', MLP_C)])\n",
    "    scores = cross_val_score(clf, epochs_data_train, labels, cv=cv, n_jobs=1)\n",
    "    \n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "    y_train_copy = y_train.copy()\n",
    "    \n",
    "    print(y_train)\n",
    "    for i in range(len(y_train)):\n",
    "        if -1 == y_train[i]:\n",
    "            y_train_copy[i] = 0\n",
    "        else:\n",
    "            y_train_copy[i] = 1\n",
    "    \n",
    "    \n",
    "    clf.fit(X_train, y_train_copy)\n",
    "    pred = clf.predict(X_test)\n",
    "    rmse_train = float(format(np.sqrt(metrics.mean_squared_error(clf.predict(X_train), y_train_copy)),'.3f'))\n",
    "    print(\"rmse_train:\",rmse_train)\n",
    "    r2_train = float(format(clf.score(X_train, y_train_copy),'.3f'))\n",
    "    print(\"r2_train:\",r2_train)\n",
    "    # ar2_train = float(format(adjustedR2(clf.score(X_train, y_train),X_train.shape[0],3),'.3f'))\n",
    "    mae_train=float(format((metrics.mean_absolute_error(clf.predict(X_train), y_train_copy)),'.3f'))\n",
    "    print(\"mae_train:\",mae_train)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    y_test_copy = y_test.copy()\n",
    "    \n",
    "    print(y_test)\n",
    "    for i in range(len(y_test)):\n",
    "        if -1 == y_test[i]:\n",
    "            y_test_copy[i] = 0\n",
    "        else:\n",
    "            y_test_copy[i] = 1\n",
    "    print(y_test_copy)\n",
    "    print('__________________________________________________________________________________')\n",
    "    \n",
    "    \n",
    "    \n",
    "    rmse_test = float(format(np.sqrt(metrics.mean_squared_error(clf.predict(X_test), y_test_copy)),'.3f'))\n",
    "    print(\"rmse_test:\",rmse_test)\n",
    "    r2_test = float(format(clf.score(X_test, y_test_copy),'.3f'))\n",
    "    print(\"r2_test:\",r2_test)\n",
    "    # ar2_test = float(format(adjustedR2(clf.score(X_test, y_test),X_test.shape[0],3),'.3f'))\n",
    "    mae_test=float(format((metrics.mean_absolute_error(clf.predict(X_test), y_test_copy)),'.3f'))\n",
    "    print(\"mae_test:\",mae_test)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    cv_train = float(format(cross_val_score(clf,X_train, y_train_copy,cv=5).mean(),'.3f'))\n",
    "    print(\"cv_train:\",cv_train)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    cv_test = float(format(cross_val_score(clf,X_test, y_test_copy,cv=5).mean(),'.3f'))\n",
    "    print(\"cv_test:\",cv_test)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "\n",
    "    # Printing the results\n",
    "    class_balance = np.mean(labels == labels[0])\n",
    "    class_balance = max(class_balance, 1. - class_balance)\n",
    "    print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores), class_balance))\n",
    "    \n",
    "    #making the labels more generalized\n",
    "    \n",
    "    print('__________________________________________________________________________________')\n",
    "    print(pred)\n",
    "    \n",
    "    #confusion matrix to know which class is being predicted\n",
    "    print('__________________________________________________________________________')\n",
    "    print('confusion matrix: ', confusion_matrix(y_test_copy, pred))\n",
    "    print('__________________________________________________________________________')\n",
    "\n",
    "#     print(\"precision_score\",precision_score(pred, y_test_copy))\n",
    "    print(\"precision_score\",precision_score(y_test_copy, pred))\n",
    "#     print(\"recall_score\",recall_score(pred, y_test_copy))\n",
    "    print(\"recall_score\",recall_score(y_test_copy, pred))\n",
    "\n",
    "#     print(\"f1_score\",f1_score(pred, y_test_copy))\n",
    "    print(\"f1_score\",f1_score(y_test_copy, pred))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #new territory from here\n",
    "    y_probas = cross_val_predict(clf, X_test, y_test_copy, cv=5, method='predict_proba')\n",
    "    \n",
    "    y_test_dfs = y_probas[:, 1]\n",
    "\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test_copy, y_test_dfs)\n",
    "    #precisions, recalls, thresholds = precision_recall_curve(y_test_copy, pred)\n",
    "\n",
    "    print('precisions', precisions)\n",
    "    precisions.sort()\n",
    "    print('precisions1 -', precisions[-1])\n",
    "    print('precisions0 - ', precisions[0])\n",
    "    print('precisions', precisions.size)\n",
    "    print('recalls', recalls)\n",
    "    recalls.sort()\n",
    "    print('recalls1 -', recalls[-1])\n",
    "    print('recalls0 -', recalls[0])\n",
    "    print('recalls', recalls.size)\n",
    "    print('thresholds', thresholds)\n",
    "    thresholds.sort()\n",
    "    print('thresholds1 -', thresholds[-1])\n",
    "    print('thresholds0 -', thresholds[0])\n",
    "    print('thresholds', thresholds.size)\n",
    "    \n",
    "    #threshold precision recall graph\n",
    "    recall_90_precision = recalls[np.argmax(precisions >= 0.90)]\n",
    "    print(recall_90_precision)\n",
    "    threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)-1]\n",
    "    print(threshold_90_precision)\n",
    "\n",
    "\n",
    "#     plt.figure(figsize=(8, 4))                                                                  \n",
    "#     plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "#     plt.plot([threshold_90_precision, threshold_90_precision], [0., 0.9], \"r:\")                 \n",
    "#     plt.plot([-50, threshold_90_precision], [0.9, 0.9], \"r:\")                                \n",
    "#     plt.plot([-50, threshold_90_precision], [recall_90_precision, recall_90_precision], \"r:\")\n",
    "#     plt.plot([threshold_90_precision], [0.9], \"ro\")                                           \n",
    "#     plt.plot([threshold_90_precision], [recall_90_precision], \"ro\")                           \n",
    "#     plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plot_precision_vs_recall(precisions, recalls)\n",
    "    plt.plot([recall_90_precision, recall_90_precision], [0., 0.9], \"r:\")\n",
    "    plt.plot([0.0, recall_90_precision], [0.9, 0.9], \"r:\")\n",
    "    plt.plot([recall_90_precision], [0.9], \"ro\")\n",
    "    fig_name = \"MLP_neural_net_precision_vs_recall_\"+ f\n",
    "    save_fig(fig_name)\n",
    "    plt.show()\n",
    "    \n",
    "    #ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_copy, y_test_dfs)\n",
    "    #fpr, tpr, thresholds = roc_curve(y_test_copy, pred)\n",
    "\n",
    "    \n",
    "    #plot curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plot_roc_curve(fpr, tpr)\n",
    "    fpr_90 = fpr[np.argmax( tpr >= recall_90_precision)]\n",
    "    plt.plot([fpr_90, fpr_90], [0., recall_90_precision], \"r:\")\n",
    "    plt.plot([0.0, fpr_90], [recall_90_precision, recall_90_precision], \"r:\")\n",
    "    plt.plot([fpr_90], [recall_90_precision], \"ro\")\n",
    "    fig_name = \"MLP_neural_net_roc_curve_\"+ f\n",
    "    save_fig(fig_name)\n",
    "    plt.show()\n",
    "    \n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    print('This is the roc_auc_score', roc_auc_score(pred, y_test_dfs))\n",
    "    #roc_auc_score(y_test_copy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"code reference from the mne documentation\n",
    "https://www.researchgate.net/publication/321726030_The_Performance_Analysis_of_K-Nearest_Neighbors_K-NN_Algorithm_for_Motor_Imagery_Classification_Based_on_EEG_Signal\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#this is the Knearest neighbour classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "for f in fp:\n",
    "    raw = creatRawArray(fp[f])\n",
    "    events, labels = creatEventsArray(fp[f])\n",
    "        \n",
    "    \n",
    "    # Apply band-pass filter\n",
    "    raw.filter(low_freq, high_freq, fir_design='firwin', skip_by_annotation='edge')\n",
    "    \n",
    "    epochs = mne.Epochs(raw, events=events, event_id=event_id, tmin=tmin, tmax=tmax, baseline=None, preload=True,\n",
    "                        verbose=False)#, picks=picks)\n",
    "\n",
    "    epochs_train = epochs.copy().crop(tmin=1., tmax=2.)\n",
    "    labels = epochs.events[:, -1] - 2\n",
    "\n",
    "    # Define a monte-carlo cross-validation generator (reduce variance):\n",
    "    scores = []\n",
    "    epochs_data = epochs.get_data()\n",
    "    epochs_data_train = epochs_train.get_data()\n",
    "    \n",
    "    #shuffling the data\n",
    "    cv = ShuffleSplit(5, test_size=0.2, random_state=42)\n",
    "    cv_split = cv.split(epochs_data_train)\n",
    "    \n",
    "    #splitting the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(epochs_data_train, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Assemble a classifier\n",
    "    KNN_C = KNeighborsClassifier(n_neighbors=15, algorithm='auto', n_jobs=1, metric='chebyshev')\n",
    "    csp = CSP(n_components=len(epochs.ch_names), reg=None, log=True, norm_trace=False)\n",
    "\n",
    "    # Use scikit-learn Pipeline with cross_val_score function\n",
    "    clf = Pipeline([('CSP', csp), ('KNN_C', KNN_C)])\n",
    "    scores = cross_val_score(clf, epochs_data_train, labels, cv=cv, n_jobs=1)\n",
    "    \n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "    y_train_copy = y_train.copy()\n",
    "    \n",
    "    print(y_train)\n",
    "    for i in range(len(y_train)):\n",
    "        if -1 == y_train[i]:\n",
    "            y_train_copy[i] = 0\n",
    "        else:\n",
    "            y_train_copy[i] = 1\n",
    "    \n",
    "    \n",
    "    clf.fit(X_train, y_train_copy)\n",
    "    pred = clf.predict(X_test)\n",
    "    rmse_train = float(format(np.sqrt(metrics.mean_squared_error(clf.predict(X_train), y_train_copy)),'.3f'))\n",
    "    print(\"rmse_train:\",rmse_train)\n",
    "    r2_train = float(format(clf.score(X_train, y_train_copy),'.3f'))\n",
    "    print(\"r2_train:\",r2_train)\n",
    "    # ar2_train = float(format(adjustedR2(clf.score(X_train, y_train),X_train.shape[0],3),'.3f'))\n",
    "    mae_train=float(format((metrics.mean_absolute_error(clf.predict(X_train), y_train_copy)),'.3f'))\n",
    "    print(\"mae_train:\",mae_train)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    y_test_copy = y_test.copy()\n",
    "    \n",
    "    print(y_test)\n",
    "    for i in range(len(y_test)):\n",
    "        if -1 == y_test[i]:\n",
    "            y_test_copy[i] = 0\n",
    "        else:\n",
    "            y_test_copy[i] = 1\n",
    "    print(y_test_copy)\n",
    "    print('__________________________________________________________________________________')\n",
    "    \n",
    "    \n",
    "    \n",
    "    rmse_test = float(format(np.sqrt(metrics.mean_squared_error(clf.predict(X_test), y_test_copy)),'.3f'))\n",
    "    print(\"rmse_test:\",rmse_test)\n",
    "    r2_test = float(format(clf.score(X_test, y_test_copy),'.3f'))\n",
    "    print(\"r2_test:\",r2_test)\n",
    "    # ar2_test = float(format(adjustedR2(clf.score(X_test, y_test),X_test.shape[0],3),'.3f'))\n",
    "    mae_test=float(format((metrics.mean_absolute_error(clf.predict(X_test), y_test_copy)),'.3f'))\n",
    "    print(\"mae_test:\",mae_test)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    cv_train = float(format(cross_val_score(clf,X_train, y_train_copy,cv=5).mean(),'.3f'))\n",
    "    print(\"cv_train:\",cv_train)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    cv_test = float(format(cross_val_score(clf,X_test, y_test_copy,cv=5).mean(),'.3f'))\n",
    "    print(\"cv_test:\",cv_test)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "\n",
    "    # Printing the results\n",
    "    class_balance = np.mean(labels == labels[0])\n",
    "    class_balance = max(class_balance, 1. - class_balance)\n",
    "    print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores), class_balance))\n",
    "    \n",
    "    #making the labels more generalized\n",
    "    \n",
    "    print('__________________________________________________________________________________')\n",
    "    print(pred)\n",
    "    \n",
    "    #confusion matrix to know which class is being predicted\n",
    "    print('__________________________________________________________________________')\n",
    "    print('confusion matrix: ', confusion_matrix(y_test_copy, pred))\n",
    "    print('__________________________________________________________________________')\n",
    "\n",
    "#     print(\"precision_score\",precision_score(pred, y_test_copy))\n",
    "    print(\"precision_score\",precision_score(y_test_copy, pred))\n",
    "#     print(\"recall_score\",recall_score(pred, y_test_copy))\n",
    "    print(\"recall_score\",recall_score(y_test_copy, pred))\n",
    "\n",
    "#     print(\"f1_score\",f1_score(pred, y_test_copy))\n",
    "    print(\"f1_score\",f1_score(y_test_copy, pred))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #new territory from here\n",
    "    y_probas = cross_val_predict(clf, X_test, y_test_copy, cv=5, method='predict_proba')\n",
    "    \n",
    "    y_test_dfs = y_probas[:, 1]\n",
    "\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test_copy, y_test_dfs)\n",
    "    #precisions, recalls, thresholds = precision_recall_curve(y_test_copy, pred)\n",
    "\n",
    "    print('precisions', precisions)\n",
    "    precisions.sort()\n",
    "    print('precisions1 -', precisions[-1])\n",
    "    print('precisions0 - ', precisions[0])\n",
    "    print('precisions', precisions.size)\n",
    "    print('recalls', recalls)\n",
    "    recalls.sort()\n",
    "    print('recalls1 -', recalls[-1])\n",
    "    print('recalls0 -', recalls[0])\n",
    "    print('recalls', recalls.size)\n",
    "    print('thresholds', thresholds)\n",
    "    thresholds.sort()\n",
    "    print('thresholds1 -', thresholds[-1])\n",
    "    print('thresholds0 -', thresholds[0])\n",
    "    print('thresholds', thresholds.size)\n",
    "    \n",
    "    #threshold precision recall graph\n",
    "    recall_90_precision = recalls[np.argmax(precisions >= 0.90)]\n",
    "    print(recall_90_precision)\n",
    "    threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)-1]\n",
    "    print(threshold_90_precision)\n",
    "\n",
    "\n",
    "#     plt.figure(figsize=(8, 4))                                                                  \n",
    "#     plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "#     plt.plot([threshold_90_precision, threshold_90_precision], [0., 0.9], \"r:\")                 \n",
    "#     plt.plot([-50, threshold_90_precision], [0.9, 0.9], \"r:\")                                \n",
    "#     plt.plot([-50, threshold_90_precision], [recall_90_precision, recall_90_precision], \"r:\")\n",
    "#     plt.plot([threshold_90_precision], [0.9], \"ro\")                                           \n",
    "#     plt.plot([threshold_90_precision], [recall_90_precision], \"ro\")                           \n",
    "#     plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plot_precision_vs_recall(precisions, recalls)\n",
    "    plt.plot([recall_90_precision, recall_90_precision], [0., 0.9], \"r:\")\n",
    "    plt.plot([0.0, recall_90_precision], [0.9, 0.9], \"r:\")\n",
    "    plt.plot([recall_90_precision], [0.9], \"ro\")\n",
    "    fig_name = \"KNN_classifier_precision_vs_recall_\"+ f\n",
    "    save_fig(fig_name)\n",
    "    plt.show()\n",
    "    \n",
    "    #ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_copy, y_test_dfs)\n",
    "    #fpr, tpr, thresholds = roc_curve(y_test_copy, pred)\n",
    "\n",
    "    \n",
    "    #plot curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plot_roc_curve(fpr, tpr)\n",
    "    fpr_90 = fpr[np.argmax( tpr >= recall_90_precision)]\n",
    "    plt.plot([fpr_90, fpr_90], [0., recall_90_precision], \"r:\")\n",
    "    plt.plot([0.0, fpr_90], [recall_90_precision, recall_90_precision], \"r:\")\n",
    "    plt.plot([fpr_90], [recall_90_precision], \"ro\")\n",
    "    fig_name = \"KNN_classifier_roc_curve_\"+ f\n",
    "    save_fig(fig_name)\n",
    "    plt.show()\n",
    "    \n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    print('This is the roc_auc_score', roc_auc_score(pred, y_test_dfs))\n",
    "    #roc_auc_score(y_test_copy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"code reference from the mne documentation\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#this is the Decision Tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "for f in fp:\n",
    "    raw = creatRawArray(fp[f])\n",
    "    events, labels = creatEventsArray(fp[f])\n",
    "    \n",
    "    \n",
    "    # Apply band-pass filter\n",
    "    raw.filter(low_freq, high_freq, fir_design='firwin', skip_by_annotation='edge')\n",
    "\n",
    "    epochs = mne.Epochs(raw, events=events, event_id=event_id, tmin=tmin, tmax=tmax, baseline=None, preload=True,\n",
    "                        verbose=False)#, picks=picks)\n",
    "\n",
    "    epochs_train = epochs.copy().crop(tmin=1., tmax=2.)\n",
    "    labels = epochs.events[:, -1] - 2\n",
    "\n",
    "    # Define a monte-carlo cross-validation generator (reduce variance):\n",
    "    scores = []\n",
    "    epochs_data = epochs.get_data()\n",
    "    epochs_data_train = epochs_train.get_data()\n",
    "    \n",
    "    #shuffling the data\n",
    "    cv = ShuffleSplit(5, test_size=0.2, random_state=42)\n",
    "    cv_split = cv.split(epochs_data_train)\n",
    "    \n",
    "    #splitting the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(epochs_data_train, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Assemble a classifier\n",
    "    DTC = DecisionTreeClassifier(random_state=42, criterion='gini')\n",
    "    csp = CSP(n_components=len(epochs.ch_names), reg=None, log=True, norm_trace=False)\n",
    "\n",
    "    # Use scikit-learn Pipeline with cross_val_score function\n",
    "    clf = Pipeline([('CSP', csp), ('DTC', DTC)])\n",
    "    scores = cross_val_score(clf, epochs_data_train, labels, cv=cv, n_jobs=1)\n",
    "    \n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "    y_train_copy = y_train.copy()\n",
    "    \n",
    "    print(y_train)\n",
    "    for i in range(len(y_train)):\n",
    "        if -1 == y_train[i]:\n",
    "            y_train_copy[i] = 0\n",
    "        else:\n",
    "            y_train_copy[i] = 1\n",
    "    \n",
    "    \n",
    "    clf.fit(X_train, y_train_copy)\n",
    "    pred = clf.predict(X_test)\n",
    "    rmse_train = float(format(np.sqrt(metrics.mean_squared_error(clf.predict(X_train), y_train_copy)),'.3f'))\n",
    "    print(\"rmse_train:\",rmse_train)\n",
    "    r2_train = float(format(clf.score(X_train, y_train_copy),'.3f'))\n",
    "    print(\"r2_train:\",r2_train)\n",
    "    # ar2_train = float(format(adjustedR2(clf.score(X_train, y_train),X_train.shape[0],3),'.3f'))\n",
    "    mae_train=float(format((metrics.mean_absolute_error(clf.predict(X_train), y_train_copy)),'.3f'))\n",
    "    print(\"mae_train:\",mae_train)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    y_test_copy = y_test.copy()\n",
    "    \n",
    "    print(y_test)\n",
    "    for i in range(len(y_test)):\n",
    "        if -1 == y_test[i]:\n",
    "            y_test_copy[i] = 0\n",
    "        else:\n",
    "            y_test_copy[i] = 1\n",
    "    print(y_test_copy)\n",
    "    print('__________________________________________________________________________________')\n",
    "    \n",
    "    \n",
    "    \n",
    "    rmse_test = float(format(np.sqrt(metrics.mean_squared_error(clf.predict(X_test), y_test_copy)),'.3f'))\n",
    "    print(\"rmse_test:\",rmse_test)\n",
    "    r2_test = float(format(clf.score(X_test, y_test_copy),'.3f'))\n",
    "    print(\"r2_test:\",r2_test)\n",
    "    # ar2_test = float(format(adjustedR2(clf.score(X_test, y_test),X_test.shape[0],3),'.3f'))\n",
    "    mae_test=float(format((metrics.mean_absolute_error(clf.predict(X_test), y_test_copy)),'.3f'))\n",
    "    print(\"mae_test:\",mae_test)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    cv_train = float(format(cross_val_score(clf,X_train, y_train_copy,cv=5).mean(),'.3f'))\n",
    "    print(\"cv_train:\",cv_train)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    cv_test = float(format(cross_val_score(clf,X_test, y_test_copy,cv=5).mean(),'.3f'))\n",
    "    print(\"cv_test:\",cv_test)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "\n",
    "    # Printing the results\n",
    "    class_balance = np.mean(labels == labels[0])\n",
    "    class_balance = max(class_balance, 1. - class_balance)\n",
    "    print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores), class_balance))\n",
    "    \n",
    "    #making the labels more generalized\n",
    "    \n",
    "    print('__________________________________________________________________________________')\n",
    "    print(pred)\n",
    "    \n",
    "    #confusion matrix to know which class is being predicted\n",
    "    print('__________________________________________________________________________')\n",
    "    print('confusion matrix: ', confusion_matrix(y_test_copy, pred))\n",
    "    print('__________________________________________________________________________')\n",
    "\n",
    "#     print(\"precision_score\",precision_score(pred, y_test_copy))\n",
    "    print(\"precision_score\",precision_score(y_test_copy, pred))\n",
    "#     print(\"recall_score\",recall_score(pred, y_test_copy))\n",
    "    print(\"recall_score\",recall_score(y_test_copy, pred))\n",
    "\n",
    "#     print(\"f1_score\",f1_score(pred, y_test_copy))\n",
    "    print(\"f1_score\",f1_score(y_test_copy, pred))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #new territory from here\n",
    "    y_probas = cross_val_predict(clf, X_test, y_test_copy, cv=5, method='predict_proba')\n",
    "    \n",
    "    y_test_dfs = y_probas[:, 1]\n",
    "\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test_copy, y_test_dfs)\n",
    "    #precisions, recalls, thresholds = precision_recall_curve(y_test_copy, pred)\n",
    "\n",
    "    print('precisions', precisions)\n",
    "    precisions.sort()\n",
    "    print('precisions1 -', precisions[-1])\n",
    "    print('precisions0 - ', precisions[0])\n",
    "    print('precisions', precisions.size)\n",
    "    print('recalls', recalls)\n",
    "    recalls.sort()\n",
    "    print('recalls1 -', recalls[-1])\n",
    "    print('recalls0 -', recalls[0])\n",
    "    print('recalls', recalls.size)\n",
    "    print('thresholds', thresholds)\n",
    "    thresholds.sort()\n",
    "    print('thresholds1 -', thresholds[-1])\n",
    "    print('thresholds0 -', thresholds[0])\n",
    "    print('thresholds', thresholds.size)\n",
    "    \n",
    "    #threshold precision recall graph\n",
    "    recall_90_precision = recalls[np.argmax(precisions >= 0.90)]\n",
    "    print(recall_90_precision)\n",
    "    threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)-1]\n",
    "    print(threshold_90_precision)\n",
    "\n",
    "\n",
    "#     plt.figure(figsize=(8, 4))                                                                  \n",
    "#     plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "#     plt.plot([threshold_90_precision, threshold_90_precision], [0., 0.9], \"r:\")                 \n",
    "#     plt.plot([-50, threshold_90_precision], [0.9, 0.9], \"r:\")                                \n",
    "#     plt.plot([-50, threshold_90_precision], [recall_90_precision, recall_90_precision], \"r:\")\n",
    "#     plt.plot([threshold_90_precision], [0.9], \"ro\")                                           \n",
    "#     plt.plot([threshold_90_precision], [recall_90_precision], \"ro\")                           \n",
    "#     plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plot_precision_vs_recall(precisions, recalls)\n",
    "    plt.plot([recall_90_precision, recall_90_precision], [0., 0.9], \"r:\")\n",
    "    plt.plot([0.0, recall_90_precision], [0.9, 0.9], \"r:\")\n",
    "    plt.plot([recall_90_precision], [0.9], \"ro\")\n",
    "    fig_name = \"decision_tree_classifier_precision_vs_recall_\"+ f\n",
    "    save_fig(fig_name)\n",
    "    plt.show()\n",
    "    \n",
    "    #ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_copy, y_test_dfs)\n",
    "    #fpr, tpr, thresholds = roc_curve(y_test_copy, pred)\n",
    "\n",
    "    \n",
    "    #plot curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plot_roc_curve(fpr, tpr)\n",
    "    fpr_90 = fpr[np.argmax( tpr >= recall_90_precision)]\n",
    "    plt.plot([fpr_90, fpr_90], [0., recall_90_precision], \"r:\")\n",
    "    plt.plot([0.0, fpr_90], [recall_90_precision, recall_90_precision], \"r:\")\n",
    "    plt.plot([fpr_90], [recall_90_precision], \"ro\")\n",
    "    fig_name = \"Decision_tree_classifier_roc_curve_\"+ f\n",
    "    save_fig(fig_name)\n",
    "    plt.show()\n",
    "    \n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    print('This is the roc_auc_score', roc_auc_score(pred, y_test_dfs))\n",
    "    #roc_auc_score(y_test_copy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"code reference from the mne documentation\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#this is the Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "for f in fp:\n",
    "    raw = creatRawArray(fp[f])\n",
    "    events, labels = creatEventsArray(fp[f])\n",
    "    \n",
    "    # Apply band-pass filter\n",
    "    raw.filter(low_freq, high_freq, fir_design='firwin', skip_by_annotation='edge')\n",
    "    \n",
    "    epochs = mne.Epochs(raw, events=events, event_id=event_id, tmin=tmin, tmax=tmax, baseline=None, preload=True,\n",
    "                        verbose=False)#, picks=picks)\n",
    "\n",
    "    epochs_train = epochs.copy().crop(tmin=1., tmax=2.)\n",
    "    labels = epochs.events[:, -1] - 2\n",
    "\n",
    "    # Define a monte-carlo cross-validation generator (reduce variance):\n",
    "    scores = []\n",
    "    epochs_data = epochs.get_data()\n",
    "    epochs_data_train = epochs_train.get_data()\n",
    "    \n",
    "    #shuffling the data\n",
    "    cv = ShuffleSplit(5, test_size=0.2, random_state=42)\n",
    "    cv_split = cv.split(epochs_data_train)\n",
    "    \n",
    "    #splitting the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(epochs_data_train, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Assemble a classifier\n",
    "    LLR = LogisticRegression(random_state=42, penalty='l2', solver='lbfgs', verbose=0, n_jobs=1)\n",
    "    csp = CSP(n_components=len(epochs.ch_names), reg=None, log=True, norm_trace=False)\n",
    "\n",
    "    # Use scikit-learn Pipeline with cross_val_score function\n",
    "    clf = Pipeline([('CSP', csp), ('LLR', LLR)])\n",
    "    scores = cross_val_score(clf, epochs_data_train, labels, cv=cv, n_jobs=1)\n",
    "    \n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "    y_train_copy = y_train.copy()\n",
    "    \n",
    "    print(y_train)\n",
    "    for i in range(len(y_train)):\n",
    "        if -1 == y_train[i]:\n",
    "            y_train_copy[i] = 0\n",
    "        else:\n",
    "            y_train_copy[i] = 1\n",
    "    \n",
    "    \n",
    "    clf.fit(X_train, y_train_copy)\n",
    "    pred = clf.predict(X_test)\n",
    "    rmse_train = float(format(np.sqrt(metrics.mean_squared_error(clf.predict(X_train), y_train_copy)),'.3f'))\n",
    "    print(\"rmse_train:\",rmse_train)\n",
    "    r2_train = float(format(clf.score(X_train, y_train_copy),'.3f'))\n",
    "    print(\"r2_train:\",r2_train)\n",
    "    # ar2_train = float(format(adjustedR2(clf.score(X_train, y_train),X_train.shape[0],3),'.3f'))\n",
    "    mae_train=float(format((metrics.mean_absolute_error(clf.predict(X_train), y_train_copy)),'.3f'))\n",
    "    print(\"mae_train:\",mae_train)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    y_test_copy = y_test.copy()\n",
    "    \n",
    "    print(y_test)\n",
    "    for i in range(len(y_test)):\n",
    "        if -1 == y_test[i]:\n",
    "            y_test_copy[i] = 0\n",
    "        else:\n",
    "            y_test_copy[i] = 1\n",
    "    print(y_test_copy)\n",
    "    print('__________________________________________________________________________________')\n",
    "    \n",
    "    \n",
    "    \n",
    "    rmse_test = float(format(np.sqrt(metrics.mean_squared_error(clf.predict(X_test), y_test_copy)),'.3f'))\n",
    "    print(\"rmse_test:\",rmse_test)\n",
    "    r2_test = float(format(clf.score(X_test, y_test_copy),'.3f'))\n",
    "    print(\"r2_test:\",r2_test)\n",
    "    # ar2_test = float(format(adjustedR2(clf.score(X_test, y_test),X_test.shape[0],3),'.3f'))\n",
    "    mae_test=float(format((metrics.mean_absolute_error(clf.predict(X_test), y_test_copy)),'.3f'))\n",
    "    print(\"mae_test:\",mae_test)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    cv_train = float(format(cross_val_score(clf,X_train, y_train_copy,cv=5).mean(),'.3f'))\n",
    "    print(\"cv_train:\",cv_train)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    cv_test = float(format(cross_val_score(clf,X_test, y_test_copy,cv=5).mean(),'.3f'))\n",
    "    print(\"cv_test:\",cv_test)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "\n",
    "    # Printing the results\n",
    "    class_balance = np.mean(labels == labels[0])\n",
    "    class_balance = max(class_balance, 1. - class_balance)\n",
    "    print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores), class_balance))\n",
    "    \n",
    "    #making the labels more generalized\n",
    "    \n",
    "    print('__________________________________________________________________________________')\n",
    "    print(pred)\n",
    "    \n",
    "    #confusion matrix to know which class is being predicted\n",
    "    print('__________________________________________________________________________')\n",
    "    print('confusion matrix: ', confusion_matrix(y_test_copy, pred))\n",
    "    print('__________________________________________________________________________')\n",
    "\n",
    "#     print(\"precision_score\",precision_score(pred, y_test_copy))\n",
    "    print(\"precision_score\",precision_score(y_test_copy, pred))\n",
    "#     print(\"recall_score\",recall_score(pred, y_test_copy))\n",
    "    print(\"recall_score\",recall_score(y_test_copy, pred))\n",
    "\n",
    "#     print(\"f1_score\",f1_score(pred, y_test_copy))\n",
    "    print(\"f1_score\",f1_score(y_test_copy, pred))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #new territory from here\n",
    "    y_test_dfs = cross_val_predict(clf, X_test, y_test_copy, cv=5, method='decision_function')\n",
    "\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test_copy, y_test_dfs)\n",
    "    #precisions, recalls, thresholds = precision_recall_curve(y_test_copy, pred)\n",
    "\n",
    "    print('precisions', precisions)\n",
    "    precisions.sort()\n",
    "    print('precisions1 -', precisions[-1])\n",
    "    print('precisions0 - ', precisions[0])\n",
    "    print('precisions', precisions.size)\n",
    "    print('recalls', recalls)\n",
    "    recalls.sort()\n",
    "    print('recalls1 -', recalls[-1])\n",
    "    print('recalls0 -', recalls[0])\n",
    "    print('recalls', recalls.size)\n",
    "    print('thresholds', thresholds)\n",
    "    thresholds.sort()\n",
    "    print('thresholds1 -', thresholds[-1])\n",
    "    print('thresholds0 -', thresholds[0])\n",
    "    print('thresholds', thresholds.size)\n",
    "    \n",
    "    #threshold precision recall graph\n",
    "    recall_90_precision = recalls[np.argmax(precisions >= 0.90)]\n",
    "    print(recall_90_precision)\n",
    "    threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)-1]\n",
    "    print(threshold_90_precision)\n",
    "\n",
    "\n",
    "#     plt.figure(figsize=(8, 4))                                                                  \n",
    "#     plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "#     plt.plot([threshold_90_precision, threshold_90_precision], [0., 0.9], \"r:\")                 \n",
    "#     plt.plot([-50, threshold_90_precision], [0.9, 0.9], \"r:\")                                \n",
    "#     plt.plot([-50, threshold_90_precision], [recall_90_precision, recall_90_precision], \"r:\")\n",
    "#     plt.plot([threshold_90_precision], [0.9], \"ro\")                                           \n",
    "#     plt.plot([threshold_90_precision], [recall_90_precision], \"ro\")                           \n",
    "#     plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plot_precision_vs_recall(precisions, recalls)\n",
    "    plt.plot([recall_90_precision, recall_90_precision], [0., 0.9], \"r:\")\n",
    "    plt.plot([0.0, recall_90_precision], [0.9, 0.9], \"r:\")\n",
    "    plt.plot([recall_90_precision], [0.9], \"ro\")\n",
    "    fig_name = \"logistic_regression_precision_vs_recall_\"+ f\n",
    "    save_fig(fig_name)\n",
    "    plt.show()\n",
    "    \n",
    "    #ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_copy, y_test_dfs)\n",
    "    #fpr, tpr, thresholds = roc_curve(y_test_copy, pred)\n",
    "\n",
    "    \n",
    "    #plot curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plot_roc_curve(fpr, tpr)\n",
    "    fpr_90 = fpr[np.argmax( tpr >= recall_90_precision)]\n",
    "    plt.plot([fpr_90, fpr_90], [0., recall_90_precision], \"r:\")\n",
    "    plt.plot([0.0, fpr_90], [recall_90_precision, recall_90_precision], \"r:\")\n",
    "    plt.plot([fpr_90], [recall_90_precision], \"ro\")\n",
    "    fig_name = \"logistic_regression_roc_curve_\"+ f\n",
    "    save_fig(fig_name)\n",
    "    plt.show()\n",
    "    \n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    print('This is the roc_auc_score', roc_auc_score(pred, y_test_dfs))\n",
    "    #roc_auc_score(y_test_copy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"code reference from the mne documentation\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#this is the Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "for f in fp:\n",
    "    raw = creatRawArray(fp[f])\n",
    "    events, labels = creatEventsArray(fp[f])\n",
    "       \n",
    "    \n",
    "    # Apply band-pass filter\n",
    "    raw.filter(low_freq, high_freq, fir_design='firwin', skip_by_annotation='edge')\n",
    "    \n",
    "    epochs = mne.Epochs(raw, events=events, event_id=event_id, tmin=tmin, tmax=tmax, baseline=None, preload=True,\n",
    "                        verbose=False)#, picks=picks)\n",
    "\n",
    "    epochs_train = epochs.copy().crop(tmin=1., tmax=2.)\n",
    "    labels = epochs.events[:, -1] - 2\n",
    "\n",
    "    # Define a monte-carlo cross-validation generator (reduce variance):\n",
    "    scores = []\n",
    "    epochs_data = epochs.get_data()\n",
    "    epochs_data_train = epochs_train.get_data()\n",
    "    \n",
    "    #shuffling the data\n",
    "    cv = ShuffleSplit(5, test_size=0.2, random_state=42)\n",
    "    cv_split = cv.split(epochs_data_train)\n",
    "    \n",
    "    #splitting the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(epochs_data_train, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Assemble a classifier\n",
    "    GNB = GaussianNB()\n",
    "    csp = CSP(n_components=len(epochs.ch_names), reg=None, log=True, norm_trace=False)\n",
    "\n",
    "    # Use scikit-learn Pipeline with cross_val_score function\n",
    "    clf = Pipeline([('CSP', csp), ('GNB', GNB)])\n",
    "    scores = cross_val_score(clf, epochs_data_train, labels, cv=cv, n_jobs=1)\n",
    "    \n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "    y_train_copy = y_train.copy()\n",
    "    \n",
    "    print(y_train)\n",
    "    for i in range(len(y_train)):\n",
    "        if -1 == y_train[i]:\n",
    "            y_train_copy[i] = 0\n",
    "        else:\n",
    "            y_train_copy[i] = 1\n",
    "    \n",
    "    \n",
    "    clf.fit(X_train, y_train_copy)\n",
    "    pred = clf.predict(X_test)\n",
    "    rmse_train = float(format(np.sqrt(metrics.mean_squared_error(clf.predict(X_train), y_train_copy)),'.3f'))\n",
    "    print(\"rmse_train:\",rmse_train)\n",
    "    r2_train = float(format(clf.score(X_train, y_train_copy),'.3f'))\n",
    "    print(\"r2_train:\",r2_train)\n",
    "    # ar2_train = float(format(adjustedR2(clf.score(X_train, y_train),X_train.shape[0],3),'.3f'))\n",
    "    mae_train=float(format((metrics.mean_absolute_error(clf.predict(X_train), y_train_copy)),'.3f'))\n",
    "    print(\"mae_train:\",mae_train)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    y_test_copy = y_test.copy()\n",
    "    \n",
    "    print(y_test)\n",
    "    for i in range(len(y_test)):\n",
    "        if -1 == y_test[i]:\n",
    "            y_test_copy[i] = 0\n",
    "        else:\n",
    "            y_test_copy[i] = 1\n",
    "    print(y_test_copy)\n",
    "    print('__________________________________________________________________________________')\n",
    "    \n",
    "    \n",
    "    \n",
    "    rmse_test = float(format(np.sqrt(metrics.mean_squared_error(clf.predict(X_test), y_test_copy)),'.3f'))\n",
    "    print(\"rmse_test:\",rmse_test)\n",
    "    r2_test = float(format(clf.score(X_test, y_test_copy),'.3f'))\n",
    "    print(\"r2_test:\",r2_test)\n",
    "    # ar2_test = float(format(adjustedR2(clf.score(X_test, y_test),X_test.shape[0],3),'.3f'))\n",
    "    mae_test=float(format((metrics.mean_absolute_error(clf.predict(X_test), y_test_copy)),'.3f'))\n",
    "    print(\"mae_test:\",mae_test)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    cv_train = float(format(cross_val_score(clf,X_train, y_train_copy,cv=5).mean(),'.3f'))\n",
    "    print(\"cv_train:\",cv_train)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    cv_test = float(format(cross_val_score(clf,X_test, y_test_copy,cv=5).mean(),'.3f'))\n",
    "    print(\"cv_test:\",cv_test)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "\n",
    "    # Printing the results\n",
    "    class_balance = np.mean(labels == labels[0])\n",
    "    class_balance = max(class_balance, 1. - class_balance)\n",
    "    print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores), class_balance))\n",
    "    \n",
    "    #making the labels more generalized\n",
    "    \n",
    "    print('__________________________________________________________________________________')\n",
    "    print(pred)\n",
    "    \n",
    "    #confusion matrix to know which class is being predicted\n",
    "    print('__________________________________________________________________________')\n",
    "    print('confusion matrix: ', confusion_matrix(y_test_copy, pred))\n",
    "    print('__________________________________________________________________________')\n",
    "\n",
    "#     print(\"precision_score\",precision_score(pred, y_test_copy))\n",
    "    print(\"precision_score\",precision_score(y_test_copy, pred))\n",
    "#     print(\"recall_score\",recall_score(pred, y_test_copy))\n",
    "    print(\"recall_score\",recall_score(y_test_copy, pred))\n",
    "\n",
    "#     print(\"f1_score\",f1_score(pred, y_test_copy))\n",
    "    print(\"f1_score\",f1_score(y_test_copy, pred))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #new territory from here\n",
    "    y_probas = cross_val_predict(clf, X_test, y_test_copy, cv=5, method='predict_proba')\n",
    "    \n",
    "    y_test_dfs = y_probas[:, 1]\n",
    "\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test_copy, y_test_dfs)\n",
    "    #precisions, recalls, thresholds = precision_recall_curve(y_test_copy, pred)\n",
    "\n",
    "    print('precisions', precisions)\n",
    "    precisions.sort()\n",
    "    print('precisions1 -', precisions[-1])\n",
    "    print('precisions0 - ', precisions[0])\n",
    "    print('precisions', precisions.size)\n",
    "    print('recalls', recalls)\n",
    "    recalls.sort()\n",
    "    print('recalls1 -', recalls[-1])\n",
    "    print('recalls0 -', recalls[0])\n",
    "    print('recalls', recalls.size)\n",
    "    print('thresholds', thresholds)\n",
    "    thresholds.sort()\n",
    "    print('thresholds1 -', thresholds[-1])\n",
    "    print('thresholds0 -', thresholds[0])\n",
    "    print('thresholds', thresholds.size)\n",
    "    \n",
    "    #threshold precision recall graph\n",
    "    recall_90_precision = recalls[np.argmax(precisions >= 0.90)]\n",
    "    print(recall_90_precision)\n",
    "    threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)-1]\n",
    "    print(threshold_90_precision)\n",
    "\n",
    "\n",
    "#     plt.figure(figsize=(8, 4))                                                                  \n",
    "#     plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "#     plt.plot([threshold_90_precision, threshold_90_precision], [0., 0.9], \"r:\")                 \n",
    "#     plt.plot([-50, threshold_90_precision], [0.9, 0.9], \"r:\")                                \n",
    "#     plt.plot([-50, threshold_90_precision], [recall_90_precision, recall_90_precision], \"r:\")\n",
    "#     plt.plot([threshold_90_precision], [0.9], \"ro\")                                           \n",
    "#     plt.plot([threshold_90_precision], [recall_90_precision], \"ro\")                           \n",
    "#     plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plot_precision_vs_recall(precisions, recalls)\n",
    "    plt.plot([recall_90_precision, recall_90_precision], [0., 0.9], \"r:\")\n",
    "    plt.plot([0.0, recall_90_precision], [0.9, 0.9], \"r:\")\n",
    "    plt.plot([recall_90_precision], [0.9], \"ro\")\n",
    "    fig_name = \"GNB_classifier_precision_vs_recall_\"+ f\n",
    "    save_fig(fig_name)\n",
    "    plt.show()\n",
    "    \n",
    "    #ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_copy, y_test_dfs)\n",
    "    #fpr, tpr, thresholds = roc_curve(y_test_copy, pred)\n",
    "\n",
    "    \n",
    "    #plot curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plot_roc_curve(fpr, tpr)\n",
    "    fpr_90 = fpr[np.argmax( tpr >= recall_90_precision)]\n",
    "    plt.plot([fpr_90, fpr_90], [0., recall_90_precision], \"r:\")\n",
    "    plt.plot([0.0, fpr_90], [recall_90_precision, recall_90_precision], \"r:\")\n",
    "    plt.plot([fpr_90], [recall_90_precision], \"ro\")\n",
    "    fig_name = \"GNB_classifier_roc_curve_\"+ f\n",
    "    save_fig(fig_name)\n",
    "    plt.show()\n",
    "    \n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    print('This is the roc_auc_score', roc_auc_score(pred, y_test_dfs))\n",
    "    #roc_auc_score(y_test_copy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"code reference from the mne documentation\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#this is the Bernoulli Naive Bayes\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "\n",
    "for f in fp:\n",
    "    raw = creatRawArray(fp[f])\n",
    "    events, labels = creatEventsArray(fp[f])    \n",
    "    \n",
    "    # Apply band-pass filter\n",
    "    raw.filter(low_freq, high_freq, fir_design='firwin', skip_by_annotation='edge')\n",
    "    \n",
    "    epochs = mne.Epochs(raw, events=events, event_id=event_id, tmin=tmin, tmax=tmax, baseline=None, preload=True,\n",
    "                        verbose=False)#, picks=picks)\n",
    "\n",
    "    epochs_train = epochs.copy().crop(tmin=1., tmax=2.)\n",
    "    labels = epochs.events[:, -1] - 2\n",
    "\n",
    "    # Define a monte-carlo cross-validation generator (reduce variance):\n",
    "    scores = []\n",
    "    epochs_data = epochs.get_data()\n",
    "    epochs_data_train = epochs_train.get_data()\n",
    "    \n",
    "    #shuffling the data\n",
    "    cv = ShuffleSplit(5, test_size=0.2, random_state=42)\n",
    "    cv_split = cv.split(epochs_data_train)\n",
    "    \n",
    "    #splitting the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(epochs_data_train, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Assemble a classifier\n",
    "    BNB = BernoulliNB()\n",
    "    csp = CSP(n_components=len(epochs.ch_names), reg=None, log=True, norm_trace=False)\n",
    "\n",
    "    # Use scikit-learn Pipeline with cross_val_score function\n",
    "    clf = Pipeline([('CSP', csp), ('BNB', BNB)])\n",
    "    scores = cross_val_score(clf, epochs_data_train, labels, cv=cv, n_jobs=1)\n",
    "    \n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "    y_train_copy = y_train.copy()\n",
    "    \n",
    "    print(y_train)\n",
    "    for i in range(len(y_train)):\n",
    "        if -1 == y_train[i]:\n",
    "            y_train_copy[i] = 0\n",
    "        else:\n",
    "            y_train_copy[i] = 1\n",
    "    \n",
    "    \n",
    "    clf.fit(X_train, y_train_copy)\n",
    "    pred = clf.predict(X_test)\n",
    "    rmse_train = float(format(np.sqrt(metrics.mean_squared_error(clf.predict(X_train), y_train_copy)),'.3f'))\n",
    "    print(\"rmse_train:\",rmse_train)\n",
    "    r2_train = float(format(clf.score(X_train, y_train_copy),'.3f'))\n",
    "    print(\"r2_train:\",r2_train)\n",
    "    # ar2_train = float(format(adjustedR2(clf.score(X_train, y_train),X_train.shape[0],3),'.3f'))\n",
    "    mae_train=float(format((metrics.mean_absolute_error(clf.predict(X_train), y_train_copy)),'.3f'))\n",
    "    print(\"mae_train:\",mae_train)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    y_test_copy = y_test.copy()\n",
    "    \n",
    "    print(y_test)\n",
    "    for i in range(len(y_test)):\n",
    "        if -1 == y_test[i]:\n",
    "            y_test_copy[i] = 0\n",
    "        else:\n",
    "            y_test_copy[i] = 1\n",
    "    print(y_test_copy)\n",
    "    print('__________________________________________________________________________________')\n",
    "    \n",
    "    \n",
    "    \n",
    "    rmse_test = float(format(np.sqrt(metrics.mean_squared_error(clf.predict(X_test), y_test_copy)),'.3f'))\n",
    "    print(\"rmse_test:\",rmse_test)\n",
    "    r2_test = float(format(clf.score(X_test, y_test_copy),'.3f'))\n",
    "    print(\"r2_test:\",r2_test)\n",
    "    # ar2_test = float(format(adjustedR2(clf.score(X_test, y_test),X_test.shape[0],3),'.3f'))\n",
    "    mae_test=float(format((metrics.mean_absolute_error(clf.predict(X_test), y_test_copy)),'.3f'))\n",
    "    print(\"mae_test:\",mae_test)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    cv_train = float(format(cross_val_score(clf,X_train, y_train_copy,cv=5).mean(),'.3f'))\n",
    "    print(\"cv_train:\",cv_train)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    cv_test = float(format(cross_val_score(clf,X_test, y_test_copy,cv=5).mean(),'.3f'))\n",
    "    print(\"cv_test:\",cv_test)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "\n",
    "    # Printing the results\n",
    "    class_balance = np.mean(labels == labels[0])\n",
    "    class_balance = max(class_balance, 1. - class_balance)\n",
    "    print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores), class_balance))\n",
    "    \n",
    "    #making the labels more generalized\n",
    "    \n",
    "    print('__________________________________________________________________________________')\n",
    "    print(pred)\n",
    "    \n",
    "    #confusion matrix to know which class is being predicted\n",
    "    print('__________________________________________________________________________')\n",
    "    print('confusion matrix: ', confusion_matrix(y_test_copy, pred))\n",
    "    print('__________________________________________________________________________')\n",
    "\n",
    "#     print(\"precision_score\",precision_score(pred, y_test_copy))\n",
    "    print(\"precision_score\",precision_score(y_test_copy, pred))\n",
    "#     print(\"recall_score\",recall_score(pred, y_test_copy))\n",
    "    print(\"recall_score\",recall_score(y_test_copy, pred))\n",
    "\n",
    "#     print(\"f1_score\",f1_score(pred, y_test_copy))\n",
    "    print(\"f1_score\",f1_score(y_test_copy, pred))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #new territory from here\n",
    "    y_probas = cross_val_predict(clf, X_test, y_test_copy, cv=5, method='predict_proba')\n",
    "    \n",
    "    y_test_dfs = y_probas[:, 1]\n",
    "\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test_copy, y_test_dfs)\n",
    "    #precisions, recalls, thresholds = precision_recall_curve(y_test_copy, pred)\n",
    "\n",
    "    print('precisions', precisions)\n",
    "    precisions.sort()\n",
    "    print('precisions1 -', precisions[-1])\n",
    "    print('precisions0 - ', precisions[0])\n",
    "    print('precisions', precisions.size)\n",
    "    print('recalls', recalls)\n",
    "    recalls.sort()\n",
    "    print('recalls1 -', recalls[-1])\n",
    "    print('recalls0 -', recalls[0])\n",
    "    print('recalls', recalls.size)\n",
    "    print('thresholds', thresholds)\n",
    "    thresholds.sort()\n",
    "    print('thresholds1 -', thresholds[-1])\n",
    "    print('thresholds0 -', thresholds[0])\n",
    "    print('thresholds', thresholds.size)\n",
    "    \n",
    "    #threshold precision recall graph\n",
    "    recall_90_precision = recalls[np.argmax(precisions >= 0.90)]\n",
    "    print(recall_90_precision)\n",
    "    threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)-1]\n",
    "    print(threshold_90_precision)\n",
    "\n",
    "\n",
    "#     plt.figure(figsize=(8, 4))                                                                  \n",
    "#     plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "#     plt.plot([threshold_90_precision, threshold_90_precision], [0., 0.9], \"r:\")                 \n",
    "#     plt.plot([-50, threshold_90_precision], [0.9, 0.9], \"r:\")                                \n",
    "#     plt.plot([-50, threshold_90_precision], [recall_90_precision, recall_90_precision], \"r:\")\n",
    "#     plt.plot([threshold_90_precision], [0.9], \"ro\")                                           \n",
    "#     plt.plot([threshold_90_precision], [recall_90_precision], \"ro\")                           \n",
    "#     plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plot_precision_vs_recall(precisions, recalls)\n",
    "    plt.plot([recall_90_precision, recall_90_precision], [0., 0.9], \"r:\")\n",
    "    plt.plot([0.0, recall_90_precision], [0.9, 0.9], \"r:\")\n",
    "    plt.plot([recall_90_precision], [0.9], \"ro\")\n",
    "    fig_name = \"BNB_classifier_precision_vs_recall_\"+ f\n",
    "    save_fig(fig_name)\n",
    "    plt.show()\n",
    "    \n",
    "    #ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_copy, y_test_dfs)\n",
    "    #fpr, tpr, thresholds = roc_curve(y_test_copy, pred)\n",
    "\n",
    "    \n",
    "    #plot curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plot_roc_curve(fpr, tpr)\n",
    "    fpr_90 = fpr[np.argmax( tpr >= recall_90_precision)]\n",
    "    plt.plot([fpr_90, fpr_90], [0., recall_90_precision], \"r:\")\n",
    "    plt.plot([0.0, fpr_90], [recall_90_precision, recall_90_precision], \"r:\")\n",
    "    plt.plot([fpr_90], [recall_90_precision], \"ro\")\n",
    "    fig_name = \"BNB_classifier_roc_curve_\"+ f\n",
    "    save_fig(fig_name)\n",
    "    plt.show()\n",
    "    \n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    print('This is the roc_auc_score', roc_auc_score(pred, y_test_dfs))\n",
    "    #roc_auc_score(y_test_copy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
